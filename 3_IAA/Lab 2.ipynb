{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratorio 2: Armado de un esquema de aprendizaje automático\n",
    "\n",
    "En el laboratorio final se espera que puedan poner en práctica los conocimientos adquiridos en el curso, trabajando con un conjunto de datos de clasificación.\n",
    "\n",
    "El objetivo es que se introduzcan en el desarrollo de un esquema para hacer tareas de aprendizaje automático: selección de un modelo, ajuste de hiperparámetros y evaluación.\n",
    "\n",
    "El conjunto de datos a utilizar está en `./data/loan_data.csv`. Si abren el archivo verán que al principio (las líneas que empiezan con `#`) describen el conjunto de datos y sus atributos (incluyendo el atributo de etiqueta o clase).\n",
    "\n",
    "Se espera que hagan uso de las herramientas vistas en el curso. Se espera que hagan uso especialmente de las herramientas brindadas por `scikit-learn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# TODO: Agregar las librerías que hagan falta\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de datos y división en entrenamiento y evaluación\n",
    "\n",
    "La celda siguiente se encarga de la carga de datos (haciendo uso de pandas). Estos serán los que se trabajarán en el resto del laboratorio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"./data/loan_data.csv\", comment=\"#\")\n",
    "\n",
    "# División entre instancias y etiquetas\n",
    "X, y = dataset.iloc[:, 1:], dataset.TARGET\n",
    "\n",
    "# división entre entrenamiento y evaluación\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify= dataset.TARGET, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"datapoints for training: {len(X_train)}\")\n",
    "print(f\"datapoints for testing: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Documentación:\n",
    "\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1: Descripción de los Datos y la Tarea\n",
    "\n",
    "Responder las siguientes preguntas:\n",
    "\n",
    "1. ¿De qué se trata el conjunto de datos?\n",
    "2. ¿Cuál es la variable objetivo que hay que predecir? ¿Qué significado tiene?\n",
    "3. ¿Qué información (atributos) hay disponible para hacer la predicción?\n",
    "4. ¿Qué atributos imagina ud. que son los más determinantes para la predicción?\n",
    "\n",
    "**No hace falta escribir código para responder estas preguntas.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Se quiere construir un predictor que tome decisiones para aprobrar creditos hipotercarios de vivienda. Conocidos como HELOC los cuales se caracterizan a menudo por tener una tasa de interés más baja que otros tipos comunes de préstamos, y su interés puede ser deducible de impuestos. Cada registro consiste en diversos datos del credito otorgado a través del proceso actual de concesión de préstamos.   \n",
    "\n",
    "\n",
    "2. La variable objetivo que se quiere predecir es Target, la cual es una variable binaria indica si el solicitante finalmente incumplió con el credito hipotecario (1) o pago el credito (0). El incumplimiento del pago se encuentra en 1189 casos.  \n",
    "\n",
    "\n",
    "\n",
    "3. Los atributos del dataset son los siguientes\n",
    "\n",
    "LOAN: Monto solicitado del préstamo.\n",
    "\n",
    "MORTDUE: Monto adeudado de la hipoteca existente.\n",
    "\n",
    "VALUE: Valor de la propiedad actual.\n",
    "\n",
    "YOJ: Años en el trabajo actual.\n",
    "\n",
    "DEROG: Número de informes despectivos importantes, la cual indica una morosidad grave o retrasos en los pagos.\n",
    "\n",
    "DELINQ: Número de líneas de crédito morosas. Una línea de crédito se vuelve morosa cuando un prestatario no realiza los pagos mínimos requeridos entre 30 y 60 días después del día en que vencían los pagos.\n",
    "\n",
    "CLAGE: Edad de la línea crédito más antigua en meses.\n",
    "\n",
    "NINQ: Número de líneas de crédito recientes.\n",
    "\n",
    "CLNO: Número de líneas de crédito existentes.\n",
    "\n",
    "DEBTINC: Relación deuda-ingresos. (todos los pagos mensuales de su deuda divididos por su ingreso bruto mensual). Este número es una forma en que los prestamistas miden su capacidad para administrar los pagos mensuales para pagar el dinero que planea pedir prestado\n",
    "\n",
    "\n",
    "4. Creemos que los atributos que nos ayudaran a predecir si se incumplio o no con el pago del credito son el monto del prestamo (`Loan`), la relacion deuda-ingresos `DEBTINC`y el número de lineas de crédito mosoras `DELINQ`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2: Predicción con Modelos Lineales\n",
    "\n",
    "En este ejercicio se entrenarán modelos lineales de clasificación para predecir la variable objetivo.\n",
    "\n",
    "Para ello, deberán utilizar la clase SGDClassifier de scikit-learn.\n",
    "\n",
    "Documentación:\n",
    "- https://scikit-learn.org/stable/modules/sgd.html\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 2.1: SGDClassifier con hiperparámetros por defecto\n",
    "\n",
    "Entrenar y evaluar el clasificador SGDClassifier usando los valores por omisión de scikit-learn para todos los parámetros. Únicamente **fijar la semilla aleatoria** para hacer repetible el experimento.\n",
    "\n",
    "Evaluar sobre el conjunto de **entrenamiento** y sobre el conjunto de **evaluación**, reportando:\n",
    "- Accuracy\n",
    "- Precision\n",
    "- Recall\n",
    "- F1\n",
    "- matriz de confusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SGDClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "classes = model.classes_\n",
    "print(classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (accuracy_score,\n",
    "                             classification_report,\n",
    "                             ConfusionMatrixDisplay,\n",
    "                             accuracy_score,\n",
    "                             f1_score,\n",
    "                             recall_score,\n",
    "                             precision_score\n",
    "                             )\n",
    "\n",
    "# Calcular métricas de evaluación\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "\n",
    "# Parametros por defecto\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Precision:\", precision)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes =[1, 0] \n",
    "\n",
    "display=ConfusionMatrixDisplay.from_predictions(\n",
    "    y_test, y_pred, labels=classes, cmap=plt.cm.BuGn, xticks_rotation='vertical')\n",
    "print(classification_report(y_test, y_pred, labels=classes))\n",
    "\n",
    "plt.title('Matriz de Confusión')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver, con los hiperparámetros por defecto de SGDClassifier, el modelo no aprende nada, prediciendo siempre lo mismo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 2.2: Ajuste de Hiperparámetros\n",
    "\n",
    "Seleccionar valores para los hiperparámetros principales del SGDClassifier. Como mínimo, probar diferentes funciones de loss, tasas de entrenamiento y tasas de regularización.\n",
    "\n",
    "Para ello, usar grid-search y 5-fold cross-validation sobre el conjunto de entrenamiento para explorar muchas combinaciones posibles de valores.\n",
    "\n",
    "Reportar accuracy promedio y varianza para todas las configuraciones.\n",
    "\n",
    "Para la mejor configuración encontrada, evaluar sobre el conjunto de **entrenamiento** y sobre el conjunto de **evaluación**, reportando:\n",
    "- Accuracy\n",
    "- Precision\n",
    "- Recall\n",
    "- F1\n",
    "- matriz de confusión\n",
    "\n",
    "Documentación:\n",
    "- https://scikit-learn.org/stable/modules/grid_search.html\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X, y):\n",
    "    model.fit(X, y)\n",
    "    y_pred = model.predict(X)\n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "    f1 = f1_score(y, y_pred)\n",
    "    recall = recall_score(y, y_pred)\n",
    "    precision = precision_score(y, y_pred)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"F1 Score:\", f1)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"Precision:\", precision)\n",
    "    print(classification_report(y, y_pred, labels=classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SGDClassifier(random_state=42)\n",
    "space = {\n",
    "    'loss': ['hinge','log_loss', 'perceptron', 'squared_error'],\n",
    "    'alpha': np.logspace(-5, 3, num=17,  base=10 ,endpoint=True, dtype=None),\n",
    "    'learning_rate': ['constant','adaptive', 'optimal'],\n",
    "    'eta0': np.logspace(-5, 3, num=17,  base=10 ,endpoint=True, dtype=None),\n",
    "}\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid = GridSearchCV(model, space, cv=5, verbose=1, n_jobs=-1,scoring='f1')\n",
    "grid.fit(X_train, y_train) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = grid.cv_results_\n",
    "for mean_score, std_dev, params in zip(results[\"mean_test_score\"], results[\"std_test_score\"], results[\"params\"]):\n",
    "    print(f\"for {params}\\n{mean_score:.3f} (+/-{std_dev*2:.03f})\\n\")\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid.best_params_)\n",
    "# for {'alpha': 0.001, 'eta0': 0.001, 'learning_rate': 'constant', 'loss': 'log_loss'} \n",
    "# 0.832 (+/-0.013)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best=grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SGDClassifier(random_state=42,**best)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "classes = model.classes_\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (accuracy_score,\n",
    "                             classification_report,\n",
    "                             ConfusionMatrixDisplay,\n",
    "                             accuracy_score,\n",
    "                             f1_score,\n",
    "                             recall_score,\n",
    "                             precision_score\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular métricas de evaluación\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "\n",
    "# Parametros por defecto\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Precision:\", precision)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes =[1, 0] \n",
    "\n",
    "display=ConfusionMatrixDisplay.from_predictions(\n",
    "    y_test, y_pred, labels=classes, cmap=plt.cm.BuGn)\n",
    "print(classification_report(y_test, y_pred, labels=classes))\n",
    "\n",
    "plt.title('Matriz de Confusión')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 3: Árboles de Decisión\n",
    "\n",
    "En este ejercicio se entrenarán árboles de decisión para predecir la variable objetivo.\n",
    "\n",
    "Para ello, deberán utilizar la clase DecisionTreeClassifier de scikit-learn.\n",
    "\n",
    "Documentación:\n",
    "- https://scikit-learn.org/stable/modules/tree.html\n",
    "  - https://scikit-learn.org/stable/modules/tree.html#tips-on-practical-use\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "- https://scikit-learn.org/stable/auto_examples/tree/plot_unveil_tree_structure.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 3.1: DecisionTreeClassifier con hiperparámetros por defecto\n",
    "\n",
    "Entrenar y evaluar el clasificador DecisionTreeClassifier usando los valores por omisión de scikit-learn para todos los parámetros. Únicamente **fijar la semilla aleatoria** para hacer repetible el experimento.\n",
    "\n",
    "Evaluar sobre el conjunto de **entrenamiento** y sobre el conjunto de **evaluación**, reportando:\n",
    "- Accuracy\n",
    "- Precision\n",
    "- Recall\n",
    "- F1\n",
    "- matriz de confusión\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "\n",
    "model_tree= tree.DecisionTreeClassifier(random_state=42)\n",
    "model_tree.fit(X_train,y_train)\n",
    "y_pred=model_tree.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular métricas de evaluación\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Precision:\", precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes =[1, 0] \n",
    "\n",
    "display=ConfusionMatrixDisplay.from_predictions(\n",
    "    y_test, y_pred, labels=classes, cmap=plt.cm.BuGn, xticks_rotation='vertical')\n",
    "print(classification_report(y_test, y_pred, labels=classes))\n",
    "\n",
    "plt.title('Matriz de Confusión')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 3.2: Ajuste de Hiperparámetros\n",
    "\n",
    "Seleccionar valores para los hiperparámetros principales del DecisionTreeClassifier. Como mínimo, probar diferentes criterios de partición (criterion), profundidad máxima del árbol (max_depth), y cantidad mínima de samples por hoja (min_samples_leaf).\n",
    "\n",
    "Para ello, usar grid-search y 5-fold cross-validation sobre el conjunto de entrenamiento para explorar muchas combinaciones posibles de valores.\n",
    "\n",
    "Reportar accuracy promedio y varianza para todas las configuraciones.\n",
    "\n",
    "Para la mejor configuración encontrada, evaluar sobre el conjunto de **entrenamiento** y sobre el conjunto de **evaluación**, reportando:\n",
    "- Accuracy\n",
    "- Precision\n",
    "- Recall\n",
    "- F1\n",
    "- matriz de confusión\n",
    "\n",
    "\n",
    "Documentación:\n",
    "- https://scikit-learn.org/stable/modules/grid_search.html\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrica utilizada F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tree.DecisionTreeClassifier(random_state=42)\n",
    "space = {\n",
    "    'criterion': ['gini','entropy'],\n",
    "    'max_depth': np.arange(2,20,1),\n",
    "    'min_samples_split':np.arange(2,22,1),\n",
    "    'min_samples_leaf':np.arange(2,22,1)\n",
    "}\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid = GridSearchCV(model, space, cv=5, verbose=1, n_jobs=-1,scoring='f1')\n",
    "grid.fit(X_train, y_train) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = grid.cv_results_\n",
    "for mean_score, std_dev, params in zip(results[\"mean_test_score\"], results[\"std_test_score\"], results[\"params\"]):\n",
    "    print(f\"for {params}\\n{mean_score:.3f} (+/-{std_dev*2:.03f})\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treeCV=tree.DecisionTreeClassifier(random_state=42,**grid.best_params_)\n",
    "treeCV.fit(X_train,y_train)\n",
    "y_pred=treeCV.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular métricas de evaluación\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Precision:\", precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [1,0]\n",
    "\n",
    "display=ConfusionMatrixDisplay.from_predictions(\n",
    "    y_test, y_pred, labels=classes, cmap=plt.cm.BuGn)\n",
    "print(classification_report(y_test, y_pred, labels=classes))\n",
    "\n",
    "plt.title('Matriz de Confusión')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrica utilizada Balanced Accuracy \n",
    "\n",
    "The balanced accuracy in binary and multiclass classification problems to deal with imbalanced datasets. It is defined as the average of recall obtained on each class.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tree.DecisionTreeClassifier(random_state=42)\n",
    "space = {\n",
    "    'criterion': ['gini','entropy'],\n",
    "    'max_depth': np.arange(2,30,1),\n",
    "    'min_samples_split':np.arange(2,22,1),\n",
    "    'min_samples_leaf':np.arange(2,22,1)\n",
    "}\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid1 = GridSearchCV(model, space, cv=5, verbose=1, n_jobs=-1,scoring='balanced_accuracy')\n",
    "grid1.fit(X_train, y_train) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treeCV1=tree.DecisionTreeClassifier(random_state=42,**grid1.best_params_)\n",
    "treeCV1.fit(X_train,y_train)\n",
    "y_pred=treeCV1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Precision:\", precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes =[1, 0] \n",
    "\n",
    "display=ConfusionMatrixDisplay.from_predictions(\n",
    "    y_test, y_pred, labels=classes, cmap=plt.cm.BuGn)\n",
    "print(classification_report(y_test, y_pred, labels=classes))\n",
    "\n",
    "plt.title('Matriz de Confusión')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "clusterer= KMeans(n_clusters=2, n_init=\"auto\", random_state=42,)\n",
    "labels = clusterer.fit_predict(X)\n",
    "#algorithm{“lloyd”, “elkan”, “auto”, “full”}\n",
    "\n",
    "\n",
    "from sklearn.metrics import adjusted_rand_score,adjusted_mutual_info_score,homogeneity_score, completeness_score, v_measure_score,silhouette_score\n",
    "\n",
    "\n",
    "ari = adjusted_rand_score(y, labels)\n",
    "ami = adjusted_mutual_info_score(y, labels)\n",
    "homogeneity = homogeneity_score(y, labels)\n",
    "completeness = completeness_score(y, labels)\n",
    "v_measure = v_measure_score(y, labels)\n",
    "sil= silhouette_score(X,labels)\n",
    "\n",
    "\n",
    "print(\"Adjusted Rand Index:\", ari)\n",
    "print(\"Adjusted Mutual information:\", ami)\n",
    "print(\"Homogeneity:\", homogeneity)\n",
    "print(\"Completeness:\", completeness)\n",
    "print(\"V Measure:\", v_measure)\n",
    "print(\"Silhouette:\",sil)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
