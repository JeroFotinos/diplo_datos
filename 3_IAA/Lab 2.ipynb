{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratorio 2: Armado de un esquema de aprendizaje automático\n",
    "\n",
    "En el laboratorio final se espera que puedan poner en práctica los conocimientos adquiridos en el curso, trabajando con un conjunto de datos de clasificación.\n",
    "\n",
    "El objetivo es que se introduzcan en el desarrollo de un esquema para hacer tareas de aprendizaje automático: selección de un modelo, ajuste de hiperparámetros y evaluación.\n",
    "\n",
    "El conjunto de datos a utilizar está en `./data/loan_data.csv`. Si abren el archivo verán que al principio (las líneas que empiezan con `#`) describen el conjunto de datos y sus atributos (incluyendo el atributo de etiqueta o clase).\n",
    "\n",
    "Se espera que hagan uso de las herramientas vistas en el curso. Se espera que hagan uso especialmente de las herramientas brindadas por `scikit-learn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# TODO: Agregar las librerías que hagan falta\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de datos y división en entrenamiento y evaluación\n",
    "\n",
    "La celda siguiente se encarga de la carga de datos (haciendo uso de pandas). Estos serán los que se trabajarán en el resto del laboratorio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"./data/loan_data.csv\", comment=\"#\")\n",
    "\n",
    "# División entre instancias y etiquetas\n",
    "X, y = dataset.iloc[:, 1:], dataset.TARGET\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "# división entre entrenamiento y evaluación\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify= dataset.TARGET, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datapoints for training: 1483\n",
      "datapoints for testing: 371\n"
     ]
    }
   ],
   "source": [
    "print(f\"datapoints for training: {len(X_train)}\")\n",
    "print(f\"datapoints for testing: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Documentación:\n",
    "\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1: Descripción de los Datos y la Tarea\n",
    "\n",
    "Responder las siguientes preguntas:\n",
    "\n",
    "1. ¿De qué se trata el conjunto de datos?\n",
    "2. ¿Cuál es la variable objetivo que hay que predecir? ¿Qué significado tiene?\n",
    "3. ¿Qué información (atributos) hay disponible para hacer la predicción?\n",
    "4. ¿Qué atributos imagina ud. que son los más determinantes para la predicción?\n",
    "\n",
    "**No hace falta escribir código para responder estas preguntas.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Se quiere construir un predictor que tome decisiones para aprobrar creditos hipotercarios de vivienda. Conocidos como HELOC los cuales se caracterizan a menudo por tener una tasa de interés más baja que otros tipos comunes de préstamos, y su interés puede ser deducible de impuestos. Cada registro consiste en diversos datos del credito otorgado a través del proceso actual de concesión de préstamos.   \n",
    "\n",
    "\n",
    "2. La variable objetivo que se quiere predecir es Target, la cual es una variable binaria indica si el solicitante finalmente incumplió con el credito hipotecario (1) o pago el credito (0). El incumplimiento del pago se encuentra en 1189 casos.  \n",
    "\n",
    "\n",
    "\n",
    "3. Los atributos del dataset son los siguientes\n",
    "\n",
    "LOAN: Monto solicitado del préstamo.\n",
    "\n",
    "MORTDUE: Monto adeudado de la hipoteca existente.\n",
    "\n",
    "VALUE: Valor de la propiedad actual.\n",
    "\n",
    "YOJ: Años en el trabajo actual.\n",
    "\n",
    "DEROG: Número de informes despectivos importantes, la cual indica una morosidad grave o retrasos en los pagos.\n",
    "\n",
    "DELINQ: Número de líneas de crédito morosas. Una línea de crédito se vuelve morosa cuando un prestatario no realiza los pagos mínimos requeridos entre 30 y 60 días después del día en que vencían los pagos.\n",
    "\n",
    "CLAGE: Edad de la línea crédito más antigua en meses.\n",
    "\n",
    "NINQ: Número de líneas de crédito recientes.\n",
    "\n",
    "CLNO: Número de líneas de crédito existentes.\n",
    "\n",
    "DEBTINC: Relación deuda-ingresos. (todos los pagos mensuales de su deuda divididos por su ingreso bruto mensual). Este número es una forma en que los prestamistas miden su capacidad para administrar los pagos mensuales para pagar el dinero que planea pedir prestado\n",
    "\n",
    "\n",
    "4. Creemos que los atributos que nos ayudaran a predecir si se incumplio o no con el pago del credito son el monto del prestamo (`Loan`), la relacion deuda-ingresos `DEBTINC`y el número de lineas de crédito mosoras `DELINQ`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2: Predicción con Modelos Lineales\n",
    "\n",
    "En este ejercicio se entrenarán modelos lineales de clasificación para predecir la variable objetivo.\n",
    "\n",
    "Para ello, deberán utilizar la clase SGDClassifier de scikit-learn.\n",
    "\n",
    "Documentación:\n",
    "- https://scikit-learn.org/stable/modules/sgd.html\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 2.1: SGDClassifier con hiperparámetros por defecto\n",
    "\n",
    "Entrenar y evaluar el clasificador SGDClassifier usando los valores por omisión de scikit-learn para todos los parámetros. Únicamente **fijar la semilla aleatoria** para hacer repetible el experimento.\n",
    "\n",
    "Evaluar sobre el conjunto de **entrenamiento** y sobre el conjunto de **evaluación**, reportando:\n",
    "- Accuracy\n",
    "- Precision\n",
    "- Recall\n",
    "- F1\n",
    "- matriz de confusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "model = SGDClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "classes = model.classes_\n",
    "print(classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (accuracy_score,\n",
    "                             classification_report,\n",
    "                             ConfusionMatrixDisplay,\n",
    "                             accuracy_score,\n",
    "                             f1_score,\n",
    "                             recall_score,\n",
    "                             precision_score\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8706199460916442\n",
      "F1 Score: 0.4285714285714286\n",
      "Recall: 0.2903225806451613\n",
      "Precision: 0.8181818181818182\n",
      "Accuracy: 0.8706199460916442\n"
     ]
    }
   ],
   "source": [
    "# Calcular métricas de evaluación\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "\n",
    "# Parametros por defecto\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Precision:\", precision)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.29      0.43        62\n",
      "           0       0.87      0.99      0.93       309\n",
      "\n",
      "    accuracy                           0.87       371\n",
      "   macro avg       0.85      0.64      0.68       371\n",
      "weighted avg       0.86      0.87      0.84       371\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classes =[1, 0] \n",
    "\n",
    "display=ConfusionMatrixDisplay.from_predictions(\n",
    "    y_test, y_pred, labels=classes, cmap=plt.cm.BuGn)\n",
    "print(classification_report(y_test, y_pred, labels=classes))\n",
    "\n",
    "plt.title('Matriz de Confusión')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver, con los hiperparámetros por defecto de SGDClassifier, el modelo no aprende nada, prediciendo siempre lo mismo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 2.2: Ajuste de Hiperparámetros\n",
    "\n",
    "Seleccionar valores para los hiperparámetros principales del SGDClassifier. Como mínimo, probar diferentes funciones de loss, tasas de entrenamiento y tasas de regularización.\n",
    "\n",
    "Para ello, usar grid-search y 5-fold cross-validation sobre el conjunto de entrenamiento para explorar muchas combinaciones posibles de valores.\n",
    "\n",
    "Reportar accuracy promedio y varianza para todas las configuraciones.\n",
    "\n",
    "Para la mejor configuración encontrada, evaluar sobre el conjunto de **entrenamiento** y sobre el conjunto de **evaluación**, reportando:\n",
    "- Accuracy\n",
    "- Precision\n",
    "- Recall\n",
    "- F1\n",
    "- matriz de confusión\n",
    "\n",
    "Documentación:\n",
    "- https://scikit-learn.org/stable/modules/grid_search.html\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X, y):\n",
    "    model.fit(X, y)\n",
    "    y_pred = model.predict(X)\n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "    f1 = f1_score(y, y_pred)\n",
    "    recall = recall_score(y, y_pred)\n",
    "    precision = precision_score(y, y_pred)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"F1 Score:\", f1)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"Precision:\", precision)\n",
    "    print(classification_report(y, y_pred, labels=classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3468 candidates, totalling 17340 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=SGDClassifier(random_state=42), n_jobs=-1,\n",
       "             param_grid={&#x27;alpha&#x27;: array([1.00000000e-05, 3.16227766e-05, 1.00000000e-04, 3.16227766e-04,\n",
       "       1.00000000e-03, 3.16227766e-03, 1.00000000e-02, 3.16227766e-02,\n",
       "       1.00000000e-01, 3.16227766e-01, 1.00000000e+00, 3.16227766e+00,\n",
       "       1.00000000e+01, 3.16227766e+01, 1.00000000e+02, 3.16227766e+02,\n",
       "       1.00000000e+03]),\n",
       "                         &#x27;eta0&#x27;: array([1.00000000e-05, 3.16227766e-05, 1.00000000e-04, 3.16227766e-04,\n",
       "       1.00000000e-03, 3.16227766e-03, 1.00000000e-02, 3.16227766e-02,\n",
       "       1.00000000e-01, 3.16227766e-01, 1.00000000e+00, 3.16227766e+00,\n",
       "       1.00000000e+01, 3.16227766e+01, 1.00000000e+02, 3.16227766e+02,\n",
       "       1.00000000e+03]),\n",
       "                         &#x27;learning_rate&#x27;: [&#x27;constant&#x27;, &#x27;adaptive&#x27;, &#x27;optimal&#x27;],\n",
       "                         &#x27;loss&#x27;: [&#x27;hinge&#x27;, &#x27;log_loss&#x27;, &#x27;perceptron&#x27;,\n",
       "                                  &#x27;squared_error&#x27;]},\n",
       "             scoring=&#x27;f1&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=SGDClassifier(random_state=42), n_jobs=-1,\n",
       "             param_grid={&#x27;alpha&#x27;: array([1.00000000e-05, 3.16227766e-05, 1.00000000e-04, 3.16227766e-04,\n",
       "       1.00000000e-03, 3.16227766e-03, 1.00000000e-02, 3.16227766e-02,\n",
       "       1.00000000e-01, 3.16227766e-01, 1.00000000e+00, 3.16227766e+00,\n",
       "       1.00000000e+01, 3.16227766e+01, 1.00000000e+02, 3.16227766e+02,\n",
       "       1.00000000e+03]),\n",
       "                         &#x27;eta0&#x27;: array([1.00000000e-05, 3.16227766e-05, 1.00000000e-04, 3.16227766e-04,\n",
       "       1.00000000e-03, 3.16227766e-03, 1.00000000e-02, 3.16227766e-02,\n",
       "       1.00000000e-01, 3.16227766e-01, 1.00000000e+00, 3.16227766e+00,\n",
       "       1.00000000e+01, 3.16227766e+01, 1.00000000e+02, 3.16227766e+02,\n",
       "       1.00000000e+03]),\n",
       "                         &#x27;learning_rate&#x27;: [&#x27;constant&#x27;, &#x27;adaptive&#x27;, &#x27;optimal&#x27;],\n",
       "                         &#x27;loss&#x27;: [&#x27;hinge&#x27;, &#x27;log_loss&#x27;, &#x27;perceptron&#x27;,\n",
       "                                  &#x27;squared_error&#x27;]},\n",
       "             scoring=&#x27;f1&#x27;, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SGDClassifier</label><div class=\"sk-toggleable__content\"><pre>SGDClassifier(random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SGDClassifier</label><div class=\"sk-toggleable__content\"><pre>SGDClassifier(random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SGDClassifier(random_state=42), n_jobs=-1,\n",
       "             param_grid={'alpha': array([1.00000000e-05, 3.16227766e-05, 1.00000000e-04, 3.16227766e-04,\n",
       "       1.00000000e-03, 3.16227766e-03, 1.00000000e-02, 3.16227766e-02,\n",
       "       1.00000000e-01, 3.16227766e-01, 1.00000000e+00, 3.16227766e+00,\n",
       "       1.00000000e+01, 3.16227766e+01, 1.00000000e+02, 3.16227766e+02,\n",
       "       1.00000000e+03]),\n",
       "                         'eta0': array([1.00000000e-05, 3.16227766e-05, 1.00000000e-04, 3.16227766e-04,\n",
       "       1.00000000e-03, 3.16227766e-03, 1.00000000e-02, 3.16227766e-02,\n",
       "       1.00000000e-01, 3.16227766e-01, 1.00000000e+00, 3.16227766e+00,\n",
       "       1.00000000e+01, 3.16227766e+01, 1.00000000e+02, 3.16227766e+02,\n",
       "       1.00000000e+03]),\n",
       "                         'learning_rate': ['constant', 'adaptive', 'optimal'],\n",
       "                         'loss': ['hinge', 'log_loss', 'perceptron',\n",
       "                                  'squared_error']},\n",
       "             scoring='f1', verbose=1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SGDClassifier(random_state=42)\n",
    "space = {\n",
    "    'loss': ['hinge','log_loss', 'perceptron', 'squared_error'],\n",
    "    'alpha': np.logspace(-5, 3, num=17,  base=10 ,endpoint=True, dtype=None),\n",
    "    'learning_rate': ['constant','adaptive', 'optimal'],\n",
    "    'eta0': np.logspace(-5, 3, num=17,  base=10 ,endpoint=True, dtype=None),\n",
    "}\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid = GridSearchCV(model, space, cv=5, verbose=1, n_jobs=-1,scoring='f1')\n",
    "grid.fit(X_train, y_train) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for {'alpha': 1e-05, 'eta0': 1e-05, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.343 (+/-0.053)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 1e-05, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.413 (+/-0.094)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 1e-05, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.495 (+/-0.095)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 1e-05, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.375 (+/-0.063)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 1e-05, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.343 (+/-0.053)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 1e-05, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.413 (+/-0.094)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 1e-05, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.437 (+/-0.115)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 1e-05, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.375 (+/-0.063)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 1e-05, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.407 (+/-0.224)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 1e-05, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.384 (+/-0.231)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 1e-05, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.385 (+/-0.201)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 1e-05, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.281 (+/-0.176)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.333 (+/-0.058)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.413 (+/-0.080)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.495 (+/-0.095)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.352 (+/-0.037)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.333 (+/-0.058)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.413 (+/-0.080)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.384 (+/-0.186)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.353 (+/-0.035)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.407 (+/-0.224)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.384 (+/-0.231)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.385 (+/-0.201)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.281 (+/-0.176)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 0.0001, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.316 (+/-0.040)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 0.0001, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.407 (+/-0.094)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 0.0001, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.495 (+/-0.095)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 0.0001, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.347 (+/-0.027)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 0.0001, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.316 (+/-0.040)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 0.0001, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.403 (+/-0.084)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 0.0001, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.397 (+/-0.235)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 0.0001, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.348 (+/-0.031)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 0.0001, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.407 (+/-0.224)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 0.0001, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.384 (+/-0.231)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 0.0001, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.385 (+/-0.201)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 0.0001, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.281 (+/-0.176)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 0.00031622776601683794, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.317 (+/-0.020)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 0.00031622776601683794, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.404 (+/-0.089)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 0.00031622776601683794, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.495 (+/-0.095)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 0.00031622776601683794, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.342 (+/-0.046)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 0.00031622776601683794, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.317 (+/-0.020)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 0.00031622776601683794, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.404 (+/-0.089)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 0.00031622776601683794, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.408 (+/-0.184)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 0.00031622776601683794, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.342 (+/-0.046)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 0.00031622776601683794, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.407 (+/-0.224)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 0.00031622776601683794, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.384 (+/-0.231)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 0.00031622776601683794, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.385 (+/-0.201)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 0.00031622776601683794, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.281 (+/-0.176)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 0.001, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.380 (+/-0.036)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 0.001, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.413 (+/-0.054)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 0.001, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.495 (+/-0.095)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 0.001, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.337 (+/-0.055)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 0.001, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.392 (+/-0.036)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 0.001, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.423 (+/-0.044)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 0.001, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.371 (+/-0.073)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 0.001, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.347 (+/-0.051)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 0.001, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.407 (+/-0.224)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 0.001, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.384 (+/-0.231)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 0.001, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.385 (+/-0.201)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 0.001, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.281 (+/-0.176)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 0.0031622776601683794, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.405 (+/-0.052)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 0.0031622776601683794, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.439 (+/-0.058)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 0.0031622776601683794, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.495 (+/-0.095)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 0.0031622776601683794, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.375 (+/-0.094)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 0.0031622776601683794, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.401 (+/-0.047)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 0.0031622776601683794, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.438 (+/-0.059)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 0.0031622776601683794, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.490 (+/-0.153)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 0.0031622776601683794, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.353 (+/-0.041)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 0.0031622776601683794, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.407 (+/-0.224)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 0.0031622776601683794, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.384 (+/-0.231)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 0.0031622776601683794, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.385 (+/-0.201)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 0.0031622776601683794, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.281 (+/-0.176)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.403 (+/-0.062)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.444 (+/-0.066)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.461 (+/-0.072)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.385 (+/-0.079)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 0.01, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.416 (+/-0.047)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 0.01, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.446 (+/-0.070)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 0.01, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.406 (+/-0.096)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 0.01, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.353 (+/-0.041)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.407 (+/-0.224)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.384 (+/-0.231)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.385 (+/-0.201)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.281 (+/-0.176)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 0.03162277660168379, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.417 (+/-0.033)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 0.03162277660168379, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.471 (+/-0.075)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 0.03162277660168379, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.417 (+/-0.118)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 0.03162277660168379, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.374 (+/-0.267)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 0.03162277660168379, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.416 (+/-0.047)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 0.03162277660168379, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.451 (+/-0.049)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 0.03162277660168379, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.381 (+/-0.213)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 0.03162277660168379, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.348 (+/-0.055)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 0.03162277660168379, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.407 (+/-0.224)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 0.03162277660168379, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.384 (+/-0.231)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 0.03162277660168379, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.385 (+/-0.201)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 0.03162277660168379, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.281 (+/-0.176)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.510 (+/-0.088)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.450 (+/-0.110)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.441 (+/-0.054)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.269 (+/-0.218)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 0.1, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.416 (+/-0.047)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 0.1, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.451 (+/-0.049)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 0.1, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.416 (+/-0.277)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 0.1, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.348 (+/-0.055)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.407 (+/-0.224)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.384 (+/-0.231)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.385 (+/-0.201)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.281 (+/-0.176)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 0.31622776601683794, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.396 (+/-0.171)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 0.31622776601683794, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.429 (+/-0.139)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 0.31622776601683794, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.390 (+/-0.193)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 0.31622776601683794, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.259 (+/-0.094)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 0.31622776601683794, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.416 (+/-0.047)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 0.31622776601683794, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.452 (+/-0.045)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 0.31622776601683794, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.357 (+/-0.168)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 0.31622776601683794, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.352 (+/-0.038)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 0.31622776601683794, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.407 (+/-0.224)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 0.31622776601683794, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.384 (+/-0.231)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 0.31622776601683794, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.385 (+/-0.201)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 0.31622776601683794, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.281 (+/-0.176)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 1.0, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.394 (+/-0.103)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 1.0, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.391 (+/-0.139)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 1.0, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.383 (+/-0.139)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 1.0, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.251 (+/-0.203)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 1.0, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.421 (+/-0.050)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 1.0, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.451 (+/-0.049)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 1.0, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.424 (+/-0.090)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 1.0, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.352 (+/-0.038)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 1.0, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.407 (+/-0.224)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 1.0, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.384 (+/-0.231)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 1.0, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.385 (+/-0.201)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 1.0, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.281 (+/-0.176)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 3.1622776601683795, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.327 (+/-0.086)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 3.1622776601683795, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.358 (+/-0.232)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 3.1622776601683795, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.467 (+/-0.212)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 3.1622776601683795, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.171 (+/-0.056)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 3.1622776601683795, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.411 (+/-0.064)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 3.1622776601683795, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.451 (+/-0.049)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 3.1622776601683795, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.456 (+/-0.202)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 3.1622776601683795, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.348 (+/-0.055)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 3.1622776601683795, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.407 (+/-0.224)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 3.1622776601683795, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.384 (+/-0.231)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 3.1622776601683795, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.385 (+/-0.201)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 3.1622776601683795, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.281 (+/-0.176)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 10.0, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.382 (+/-0.121)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 10.0, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.396 (+/-0.204)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 10.0, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.369 (+/-0.178)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 10.0, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.255 (+/-0.068)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 10.0, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.415 (+/-0.068)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 10.0, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.452 (+/-0.045)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 10.0, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.394 (+/-0.210)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 10.0, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.352 (+/-0.038)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 10.0, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.407 (+/-0.224)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 10.0, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.384 (+/-0.231)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 10.0, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.385 (+/-0.201)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 10.0, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.281 (+/-0.176)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 31.622776601683793, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.448 (+/-0.133)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 31.622776601683793, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.353 (+/-0.288)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 31.622776601683793, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.322 (+/-0.080)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 31.622776601683793, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.229 (+/-0.065)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 31.622776601683793, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.415 (+/-0.068)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 31.622776601683793, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.452 (+/-0.045)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 31.622776601683793, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.370 (+/-0.120)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 31.622776601683793, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.348 (+/-0.055)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 31.622776601683793, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.407 (+/-0.224)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 31.622776601683793, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.384 (+/-0.231)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 31.622776601683793, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.385 (+/-0.201)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 31.622776601683793, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.281 (+/-0.176)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 100.0, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.349 (+/-0.283)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 100.0, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.374 (+/-0.320)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 100.0, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.387 (+/-0.260)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 100.0, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.249 (+/-0.066)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 100.0, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.416 (+/-0.047)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 100.0, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.452 (+/-0.045)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 100.0, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.454 (+/-0.063)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 100.0, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.352 (+/-0.038)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 100.0, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.407 (+/-0.224)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 100.0, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.384 (+/-0.231)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 100.0, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.385 (+/-0.201)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 100.0, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.281 (+/-0.176)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 316.22776601683796, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.344 (+/-0.240)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 316.22776601683796, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.385 (+/-0.203)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 316.22776601683796, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.369 (+/-0.164)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 316.22776601683796, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.229 (+/-0.162)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 316.22776601683796, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.416 (+/-0.047)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 316.22776601683796, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.450 (+/-0.053)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 316.22776601683796, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.400 (+/-0.136)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 316.22776601683796, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.353 (+/-0.041)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 316.22776601683796, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.407 (+/-0.224)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 316.22776601683796, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.384 (+/-0.231)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 316.22776601683796, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.385 (+/-0.201)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 316.22776601683796, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.281 (+/-0.176)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 1000.0, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.347 (+/-0.239)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 1000.0, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.444 (+/-0.099)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 1000.0, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.347 (+/-0.239)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 1000.0, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.266 (+/-0.111)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 1000.0, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.421 (+/-0.050)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 1000.0, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.452 (+/-0.045)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 1000.0, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.425 (+/-0.135)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 1000.0, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.352 (+/-0.038)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 1000.0, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.407 (+/-0.224)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 1000.0, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.384 (+/-0.231)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 1000.0, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.385 (+/-0.201)\n",
      "\n",
      "for {'alpha': 1e-05, 'eta0': 1000.0, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.281 (+/-0.176)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 1e-05, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.343 (+/-0.053)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 1e-05, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.413 (+/-0.094)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 1e-05, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.495 (+/-0.095)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 1e-05, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.375 (+/-0.063)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 1e-05, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.343 (+/-0.053)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 1e-05, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.413 (+/-0.094)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 1e-05, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.437 (+/-0.115)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 1e-05, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.375 (+/-0.063)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 1e-05, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.400 (+/-0.164)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 1e-05, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.434 (+/-0.061)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 1e-05, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.410 (+/-0.166)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 1e-05, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.284 (+/-0.094)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.333 (+/-0.058)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.413 (+/-0.080)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.495 (+/-0.095)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.352 (+/-0.037)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.333 (+/-0.058)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.413 (+/-0.080)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.397 (+/-0.235)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.353 (+/-0.035)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.400 (+/-0.164)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.434 (+/-0.061)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.410 (+/-0.166)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.284 (+/-0.094)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 0.0001, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.316 (+/-0.040)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 0.0001, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.407 (+/-0.094)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 0.0001, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.495 (+/-0.095)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 0.0001, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.347 (+/-0.027)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 0.0001, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.316 (+/-0.040)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 0.0001, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.403 (+/-0.084)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 0.0001, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.354 (+/-0.322)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 0.0001, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.348 (+/-0.031)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 0.0001, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.400 (+/-0.164)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 0.0001, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.434 (+/-0.061)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 0.0001, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.410 (+/-0.166)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 0.0001, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.284 (+/-0.094)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 0.00031622776601683794, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.317 (+/-0.020)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 0.00031622776601683794, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.404 (+/-0.089)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 0.00031622776601683794, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.495 (+/-0.095)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 0.00031622776601683794, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.342 (+/-0.046)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 0.00031622776601683794, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.317 (+/-0.020)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 0.00031622776601683794, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.404 (+/-0.089)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 0.00031622776601683794, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.366 (+/-0.050)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 0.00031622776601683794, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.342 (+/-0.046)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 0.00031622776601683794, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.400 (+/-0.164)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 0.00031622776601683794, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.434 (+/-0.061)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 0.00031622776601683794, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.410 (+/-0.166)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 0.00031622776601683794, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.284 (+/-0.094)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 0.001, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.380 (+/-0.036)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 0.001, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.413 (+/-0.054)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 0.001, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.495 (+/-0.095)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 0.001, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.337 (+/-0.055)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 0.001, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.392 (+/-0.036)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 0.001, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.418 (+/-0.045)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 0.001, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.382 (+/-0.191)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 0.001, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.347 (+/-0.051)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 0.001, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.400 (+/-0.164)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 0.001, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.434 (+/-0.061)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 0.001, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.410 (+/-0.166)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 0.001, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.284 (+/-0.094)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 0.0031622776601683794, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.403 (+/-0.051)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 0.0031622776601683794, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.439 (+/-0.058)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 0.0031622776601683794, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.477 (+/-0.036)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 0.0031622776601683794, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.375 (+/-0.094)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 0.0031622776601683794, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.401 (+/-0.047)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 0.0031622776601683794, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.438 (+/-0.059)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 0.0031622776601683794, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.401 (+/-0.098)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 0.0031622776601683794, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.353 (+/-0.041)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 0.0031622776601683794, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.400 (+/-0.164)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 0.0031622776601683794, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.434 (+/-0.061)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 0.0031622776601683794, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.410 (+/-0.166)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 0.0031622776601683794, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.284 (+/-0.094)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.417 (+/-0.065)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.444 (+/-0.066)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.454 (+/-0.065)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.385 (+/-0.079)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 0.01, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.411 (+/-0.064)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 0.01, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.446 (+/-0.070)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 0.01, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.325 (+/-0.150)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 0.01, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.353 (+/-0.041)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.400 (+/-0.164)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.434 (+/-0.061)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.410 (+/-0.166)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.284 (+/-0.094)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 0.03162277660168379, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.441 (+/-0.149)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 0.03162277660168379, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.471 (+/-0.075)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 0.03162277660168379, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.441 (+/-0.054)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 0.03162277660168379, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.374 (+/-0.267)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 0.03162277660168379, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.416 (+/-0.047)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 0.03162277660168379, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.451 (+/-0.049)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 0.03162277660168379, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.440 (+/-0.194)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 0.03162277660168379, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.348 (+/-0.055)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 0.03162277660168379, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.400 (+/-0.164)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 0.03162277660168379, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.434 (+/-0.061)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 0.03162277660168379, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.410 (+/-0.166)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 0.03162277660168379, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.284 (+/-0.094)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.483 (+/-0.105)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.450 (+/-0.110)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.390 (+/-0.193)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.269 (+/-0.218)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 0.1, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.421 (+/-0.050)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 0.1, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.451 (+/-0.049)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 0.1, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.374 (+/-0.286)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 0.1, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.348 (+/-0.055)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.400 (+/-0.164)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.434 (+/-0.061)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.410 (+/-0.166)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.284 (+/-0.094)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 0.31622776601683794, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.438 (+/-0.092)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 0.31622776601683794, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.429 (+/-0.139)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 0.31622776601683794, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.383 (+/-0.139)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 0.31622776601683794, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.235 (+/-0.088)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 0.31622776601683794, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.411 (+/-0.033)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 0.31622776601683794, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.452 (+/-0.045)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 0.31622776601683794, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.405 (+/-0.260)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 0.31622776601683794, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.352 (+/-0.038)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 0.31622776601683794, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.400 (+/-0.164)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 0.31622776601683794, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.434 (+/-0.061)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 0.31622776601683794, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.410 (+/-0.166)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 0.31622776601683794, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.284 (+/-0.094)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 1.0, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.407 (+/-0.178)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 1.0, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.391 (+/-0.122)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 1.0, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.453 (+/-0.203)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 1.0, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.240 (+/-0.076)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 1.0, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.421 (+/-0.050)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 1.0, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.451 (+/-0.049)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 1.0, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.473 (+/-0.112)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 1.0, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.352 (+/-0.038)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 1.0, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.400 (+/-0.164)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 1.0, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.434 (+/-0.061)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 1.0, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.410 (+/-0.166)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 1.0, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.284 (+/-0.094)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 3.1622776601683795, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.289 (+/-0.167)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 3.1622776601683795, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.402 (+/-0.168)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 3.1622776601683795, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.369 (+/-0.178)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 3.1622776601683795, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.248 (+/-0.106)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 3.1622776601683795, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.416 (+/-0.047)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 3.1622776601683795, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.452 (+/-0.045)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 3.1622776601683795, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.396 (+/-0.135)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 3.1622776601683795, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.348 (+/-0.055)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 3.1622776601683795, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.400 (+/-0.164)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 3.1622776601683795, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.434 (+/-0.061)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 3.1622776601683795, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.410 (+/-0.166)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 3.1622776601683795, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.284 (+/-0.094)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 10.0, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.387 (+/-0.132)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 10.0, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.396 (+/-0.132)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 10.0, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.322 (+/-0.080)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 10.0, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.246 (+/-0.150)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 10.0, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.411 (+/-0.064)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 10.0, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.446 (+/-0.070)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 10.0, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.443 (+/-0.089)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 10.0, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.352 (+/-0.038)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 10.0, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.400 (+/-0.164)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 10.0, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.434 (+/-0.061)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 10.0, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.410 (+/-0.166)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 10.0, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.284 (+/-0.094)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 31.622776601683793, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.328 (+/-0.190)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 31.622776601683793, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.428 (+/-0.238)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 31.622776601683793, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.387 (+/-0.260)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 31.622776601683793, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.197 (+/-0.139)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 31.622776601683793, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.415 (+/-0.068)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 31.622776601683793, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.452 (+/-0.045)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 31.622776601683793, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.417 (+/-0.148)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 31.622776601683793, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.353 (+/-0.041)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 31.622776601683793, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.400 (+/-0.164)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 31.622776601683793, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.434 (+/-0.061)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 31.622776601683793, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.410 (+/-0.166)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 31.622776601683793, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.284 (+/-0.094)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 100.0, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.416 (+/-0.175)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 100.0, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.324 (+/-0.298)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 100.0, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.369 (+/-0.164)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 100.0, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.250 (+/-0.208)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 100.0, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.416 (+/-0.047)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 100.0, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.450 (+/-0.053)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 100.0, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.340 (+/-0.188)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 100.0, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.353 (+/-0.041)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 100.0, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.400 (+/-0.164)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 100.0, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.434 (+/-0.061)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 100.0, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.410 (+/-0.166)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 100.0, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.284 (+/-0.094)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 316.22776601683796, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.355 (+/-0.248)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 316.22776601683796, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.335 (+/-0.264)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 316.22776601683796, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.347 (+/-0.239)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 316.22776601683796, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.248 (+/-0.234)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 316.22776601683796, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.416 (+/-0.047)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 316.22776601683796, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.451 (+/-0.049)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 316.22776601683796, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.382 (+/-0.211)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 316.22776601683796, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.353 (+/-0.066)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 316.22776601683796, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.400 (+/-0.164)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 316.22776601683796, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.434 (+/-0.061)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 316.22776601683796, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.410 (+/-0.166)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 316.22776601683796, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.284 (+/-0.094)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 1000.0, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.290 (+/-0.204)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 1000.0, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.330 (+/-0.190)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 1000.0, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.290 (+/-0.204)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 1000.0, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.292 (+/-0.191)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 1000.0, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.411 (+/-0.064)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 1000.0, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.452 (+/-0.045)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 1000.0, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.409 (+/-0.096)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 1000.0, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.352 (+/-0.038)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 1000.0, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.400 (+/-0.164)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 1000.0, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.434 (+/-0.061)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 1000.0, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.410 (+/-0.166)\n",
      "\n",
      "for {'alpha': 3.1622776601683795e-05, 'eta0': 1000.0, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.284 (+/-0.094)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 1e-05, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.343 (+/-0.053)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 1e-05, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.413 (+/-0.094)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 1e-05, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.495 (+/-0.095)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 1e-05, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.375 (+/-0.063)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 1e-05, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.343 (+/-0.053)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 1e-05, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.413 (+/-0.094)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 1e-05, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.450 (+/-0.145)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 1e-05, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.375 (+/-0.063)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 1e-05, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.410 (+/-0.147)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 1e-05, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.454 (+/-0.106)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 1e-05, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.410 (+/-0.107)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 1e-05, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.209 (+/-0.219)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.333 (+/-0.058)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.413 (+/-0.080)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.495 (+/-0.095)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.352 (+/-0.037)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.333 (+/-0.058)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.413 (+/-0.080)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.354 (+/-0.322)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.353 (+/-0.035)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.410 (+/-0.147)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.454 (+/-0.106)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.410 (+/-0.107)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.209 (+/-0.219)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 0.0001, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.316 (+/-0.040)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 0.0001, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.407 (+/-0.094)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 0.0001, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.495 (+/-0.095)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 0.0001, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.347 (+/-0.027)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 0.0001, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.316 (+/-0.040)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 0.0001, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.403 (+/-0.084)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 0.0001, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.341 (+/-0.247)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 0.0001, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.348 (+/-0.031)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 0.0001, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.410 (+/-0.147)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 0.0001, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.454 (+/-0.106)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 0.0001, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.410 (+/-0.107)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 0.0001, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.209 (+/-0.219)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 0.00031622776601683794, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.317 (+/-0.020)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 0.00031622776601683794, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.404 (+/-0.089)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 0.00031622776601683794, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.495 (+/-0.095)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 0.00031622776601683794, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.342 (+/-0.046)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 0.00031622776601683794, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.317 (+/-0.020)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 0.00031622776601683794, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.404 (+/-0.089)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 0.00031622776601683794, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.379 (+/-0.224)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 0.00031622776601683794, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.342 (+/-0.046)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 0.00031622776601683794, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.410 (+/-0.147)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 0.00031622776601683794, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.454 (+/-0.106)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 0.00031622776601683794, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.410 (+/-0.107)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 0.00031622776601683794, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.209 (+/-0.219)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 0.001, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.380 (+/-0.036)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 0.001, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.413 (+/-0.054)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 0.001, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.477 (+/-0.036)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 0.001, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.337 (+/-0.055)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 0.001, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.392 (+/-0.036)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 0.001, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.418 (+/-0.045)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 0.001, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.445 (+/-0.119)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 0.001, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.347 (+/-0.051)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 0.001, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.410 (+/-0.147)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 0.001, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.454 (+/-0.106)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 0.001, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.410 (+/-0.107)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 0.001, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.209 (+/-0.219)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 0.0031622776601683794, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.390 (+/-0.049)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 0.0031622776601683794, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.439 (+/-0.058)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 0.0031622776601683794, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.470 (+/-0.035)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 0.0031622776601683794, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.375 (+/-0.094)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 0.0031622776601683794, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.401 (+/-0.047)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 0.0031622776601683794, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.438 (+/-0.059)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 0.0031622776601683794, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.504 (+/-0.069)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 0.0031622776601683794, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.353 (+/-0.041)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 0.0031622776601683794, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.410 (+/-0.147)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 0.0031622776601683794, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.454 (+/-0.106)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 0.0031622776601683794, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.410 (+/-0.107)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 0.0031622776601683794, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.209 (+/-0.219)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.417 (+/-0.062)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.444 (+/-0.066)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.465 (+/-0.086)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.379 (+/-0.091)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 0.01, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.411 (+/-0.064)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 0.01, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.446 (+/-0.070)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 0.01, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.359 (+/-0.157)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 0.01, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.353 (+/-0.041)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.410 (+/-0.147)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.454 (+/-0.106)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.410 (+/-0.107)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.209 (+/-0.219)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 0.03162277660168379, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.442 (+/-0.099)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 0.03162277660168379, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.471 (+/-0.075)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 0.03162277660168379, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.430 (+/-0.102)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 0.03162277660168379, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.374 (+/-0.267)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 0.03162277660168379, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.411 (+/-0.064)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 0.03162277660168379, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.451 (+/-0.049)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 0.03162277660168379, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.450 (+/-0.098)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 0.03162277660168379, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.348 (+/-0.055)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 0.03162277660168379, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.410 (+/-0.147)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 0.03162277660168379, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.454 (+/-0.106)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 0.03162277660168379, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.410 (+/-0.107)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 0.03162277660168379, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.209 (+/-0.219)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.405 (+/-0.130)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.450 (+/-0.110)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.383 (+/-0.139)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.269 (+/-0.218)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 0.1, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.411 (+/-0.033)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 0.1, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.451 (+/-0.049)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 0.1, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.411 (+/-0.131)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 0.1, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.348 (+/-0.055)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.410 (+/-0.147)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.454 (+/-0.106)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.410 (+/-0.107)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.209 (+/-0.219)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 0.31622776601683794, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.436 (+/-0.077)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 0.31622776601683794, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.429 (+/-0.139)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 0.31622776601683794, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.453 (+/-0.203)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 0.31622776601683794, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.283 (+/-0.066)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 0.31622776601683794, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.421 (+/-0.050)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 0.31622776601683794, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.452 (+/-0.045)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 0.31622776601683794, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.429 (+/-0.101)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 0.31622776601683794, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.352 (+/-0.038)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 0.31622776601683794, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.410 (+/-0.147)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 0.31622776601683794, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.454 (+/-0.106)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 0.31622776601683794, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.410 (+/-0.107)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 0.31622776601683794, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.209 (+/-0.219)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 1.0, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.382 (+/-0.317)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 1.0, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.461 (+/-0.116)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 1.0, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.369 (+/-0.178)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 1.0, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.225 (+/-0.056)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 1.0, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.415 (+/-0.068)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 1.0, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.451 (+/-0.049)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 1.0, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.456 (+/-0.247)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 1.0, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.353 (+/-0.041)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 1.0, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.410 (+/-0.147)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 1.0, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.454 (+/-0.106)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 1.0, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.410 (+/-0.107)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 1.0, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.209 (+/-0.219)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 3.1622776601683795, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.422 (+/-0.176)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 3.1622776601683795, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.357 (+/-0.237)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 3.1622776601683795, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.322 (+/-0.080)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 3.1622776601683795, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.232 (+/-0.085)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 3.1622776601683795, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.406 (+/-0.053)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 3.1622776601683795, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.452 (+/-0.045)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 3.1622776601683795, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.398 (+/-0.163)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 3.1622776601683795, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.353 (+/-0.041)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 3.1622776601683795, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.410 (+/-0.147)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 3.1622776601683795, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.454 (+/-0.106)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 3.1622776601683795, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.410 (+/-0.107)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 3.1622776601683795, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.209 (+/-0.219)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 10.0, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.327 (+/-0.240)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 10.0, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.338 (+/-0.228)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 10.0, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.387 (+/-0.260)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 10.0, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.231 (+/-0.088)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 10.0, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.416 (+/-0.047)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 10.0, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.446 (+/-0.070)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 10.0, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.374 (+/-0.229)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 10.0, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.352 (+/-0.038)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 10.0, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.410 (+/-0.147)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 10.0, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.454 (+/-0.106)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 10.0, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.410 (+/-0.107)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 10.0, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.209 (+/-0.219)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 31.622776601683793, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.365 (+/-0.213)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 31.622776601683793, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.373 (+/-0.287)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 31.622776601683793, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.369 (+/-0.164)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 31.622776601683793, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.279 (+/-0.178)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 31.622776601683793, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.421 (+/-0.050)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 31.622776601683793, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.452 (+/-0.045)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 31.622776601683793, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.297 (+/-0.254)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 31.622776601683793, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.348 (+/-0.055)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 31.622776601683793, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.410 (+/-0.147)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 31.622776601683793, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.454 (+/-0.106)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 31.622776601683793, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.410 (+/-0.107)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 31.622776601683793, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.209 (+/-0.219)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 100.0, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.369 (+/-0.183)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 100.0, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.362 (+/-0.198)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 100.0, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.347 (+/-0.239)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 100.0, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.267 (+/-0.161)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 100.0, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.411 (+/-0.064)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 100.0, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.452 (+/-0.045)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 100.0, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.405 (+/-0.208)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 100.0, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.353 (+/-0.041)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 100.0, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.410 (+/-0.147)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 100.0, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.454 (+/-0.106)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 100.0, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.410 (+/-0.107)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 100.0, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.209 (+/-0.219)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 316.22776601683796, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.290 (+/-0.204)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 316.22776601683796, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.382 (+/-0.289)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 316.22776601683796, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.290 (+/-0.204)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 316.22776601683796, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.214 (+/-0.081)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 316.22776601683796, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.411 (+/-0.064)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 316.22776601683796, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.451 (+/-0.049)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 316.22776601683796, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.388 (+/-0.278)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 316.22776601683796, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.353 (+/-0.041)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 316.22776601683796, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.410 (+/-0.147)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 316.22776601683796, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.454 (+/-0.106)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 316.22776601683796, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.410 (+/-0.107)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 316.22776601683796, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.209 (+/-0.219)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 1000.0, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.319 (+/-0.151)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 1000.0, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.347 (+/-0.211)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 1000.0, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.319 (+/-0.151)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 1000.0, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.222 (+/-0.158)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 1000.0, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.415 (+/-0.068)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 1000.0, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.452 (+/-0.045)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 1000.0, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.474 (+/-0.147)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 1000.0, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.352 (+/-0.038)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 1000.0, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.410 (+/-0.147)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 1000.0, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.454 (+/-0.106)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 1000.0, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.410 (+/-0.107)\n",
      "\n",
      "for {'alpha': 0.0001, 'eta0': 1000.0, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.209 (+/-0.219)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 1e-05, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.343 (+/-0.053)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 1e-05, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.413 (+/-0.094)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 1e-05, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.495 (+/-0.095)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 1e-05, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.375 (+/-0.063)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 1e-05, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.343 (+/-0.053)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 1e-05, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.413 (+/-0.094)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 1e-05, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.450 (+/-0.145)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 1e-05, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.375 (+/-0.063)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 1e-05, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.442 (+/-0.125)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 1e-05, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.504 (+/-0.080)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 1e-05, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.380 (+/-0.241)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 1e-05, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.345 (+/-0.182)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.333 (+/-0.058)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.413 (+/-0.080)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.495 (+/-0.095)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.352 (+/-0.037)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.333 (+/-0.058)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.413 (+/-0.080)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.341 (+/-0.247)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.353 (+/-0.035)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.442 (+/-0.125)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.504 (+/-0.080)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.380 (+/-0.241)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.345 (+/-0.182)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 0.0001, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.316 (+/-0.040)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 0.0001, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.407 (+/-0.094)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 0.0001, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.495 (+/-0.095)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 0.0001, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.347 (+/-0.027)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 0.0001, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.316 (+/-0.040)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 0.0001, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.403 (+/-0.084)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 0.0001, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.370 (+/-0.200)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 0.0001, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.348 (+/-0.031)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 0.0001, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.442 (+/-0.125)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 0.0001, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.504 (+/-0.080)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 0.0001, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.380 (+/-0.241)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 0.0001, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.345 (+/-0.182)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 0.00031622776601683794, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.317 (+/-0.020)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 0.00031622776601683794, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.404 (+/-0.089)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 0.00031622776601683794, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.477 (+/-0.036)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 0.00031622776601683794, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.342 (+/-0.046)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 0.00031622776601683794, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.317 (+/-0.020)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 0.00031622776601683794, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.404 (+/-0.089)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 0.00031622776601683794, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.385 (+/-0.124)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 0.00031622776601683794, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.342 (+/-0.046)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 0.00031622776601683794, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.442 (+/-0.125)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 0.00031622776601683794, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.504 (+/-0.080)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 0.00031622776601683794, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.380 (+/-0.241)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 0.00031622776601683794, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.345 (+/-0.182)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 0.001, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.380 (+/-0.036)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 0.001, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.413 (+/-0.054)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 0.001, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.470 (+/-0.035)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 0.001, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.337 (+/-0.055)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 0.001, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.392 (+/-0.036)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 0.001, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.418 (+/-0.045)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 0.001, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.385 (+/-0.200)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 0.001, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.347 (+/-0.051)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 0.001, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.442 (+/-0.125)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 0.001, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.504 (+/-0.080)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 0.001, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.380 (+/-0.241)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 0.001, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.345 (+/-0.182)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 0.0031622776601683794, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.409 (+/-0.060)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 0.0031622776601683794, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.439 (+/-0.058)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 0.0031622776601683794, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.465 (+/-0.086)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 0.0031622776601683794, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.375 (+/-0.094)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 0.0031622776601683794, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.406 (+/-0.053)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 0.0031622776601683794, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.438 (+/-0.059)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 0.0031622776601683794, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.492 (+/-0.088)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 0.0031622776601683794, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.353 (+/-0.041)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 0.0031622776601683794, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.442 (+/-0.125)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 0.0031622776601683794, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.504 (+/-0.080)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 0.0031622776601683794, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.380 (+/-0.241)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 0.0031622776601683794, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.345 (+/-0.182)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.418 (+/-0.084)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.439 (+/-0.063)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.425 (+/-0.093)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.379 (+/-0.091)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 0.01, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.416 (+/-0.047)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 0.01, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.447 (+/-0.066)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 0.01, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.345 (+/-0.174)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 0.01, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.353 (+/-0.041)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.442 (+/-0.125)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.504 (+/-0.080)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.380 (+/-0.241)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.345 (+/-0.182)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 0.03162277660168379, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.455 (+/-0.058)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 0.03162277660168379, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.467 (+/-0.061)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 0.03162277660168379, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.383 (+/-0.139)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 0.03162277660168379, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.374 (+/-0.267)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 0.03162277660168379, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.411 (+/-0.064)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 0.03162277660168379, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.447 (+/-0.066)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 0.03162277660168379, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.328 (+/-0.052)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 0.03162277660168379, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.348 (+/-0.055)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 0.03162277660168379, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.442 (+/-0.125)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 0.03162277660168379, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.504 (+/-0.080)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 0.03162277660168379, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.380 (+/-0.241)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 0.03162277660168379, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.345 (+/-0.182)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.478 (+/-0.091)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.451 (+/-0.113)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.453 (+/-0.203)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.272 (+/-0.228)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 0.1, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.416 (+/-0.047)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 0.1, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.451 (+/-0.049)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 0.1, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.466 (+/-0.232)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 0.1, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.348 (+/-0.055)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.442 (+/-0.125)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.504 (+/-0.080)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.380 (+/-0.241)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.345 (+/-0.182)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 0.31622776601683794, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.408 (+/-0.119)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 0.31622776601683794, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.427 (+/-0.140)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 0.31622776601683794, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.369 (+/-0.178)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 0.31622776601683794, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.221 (+/-0.087)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 0.31622776601683794, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.416 (+/-0.039)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 0.31622776601683794, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.452 (+/-0.045)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 0.31622776601683794, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.482 (+/-0.075)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 0.31622776601683794, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.352 (+/-0.038)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 0.31622776601683794, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.442 (+/-0.125)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 0.31622776601683794, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.504 (+/-0.080)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 0.31622776601683794, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.380 (+/-0.241)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 0.31622776601683794, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.345 (+/-0.182)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 1.0, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.428 (+/-0.175)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 1.0, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.348 (+/-0.292)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 1.0, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.322 (+/-0.080)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 1.0, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.230 (+/-0.160)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 1.0, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.416 (+/-0.039)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 1.0, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.451 (+/-0.049)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 1.0, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.377 (+/-0.097)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 1.0, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.352 (+/-0.038)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 1.0, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.442 (+/-0.125)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 1.0, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.504 (+/-0.080)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 1.0, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.380 (+/-0.241)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 1.0, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.345 (+/-0.182)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 3.1622776601683795, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.424 (+/-0.167)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 3.1622776601683795, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.381 (+/-0.193)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 3.1622776601683795, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.387 (+/-0.260)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 3.1622776601683795, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.254 (+/-0.182)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 3.1622776601683795, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.411 (+/-0.064)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 3.1622776601683795, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.448 (+/-0.062)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 3.1622776601683795, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.386 (+/-0.133)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 3.1622776601683795, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.353 (+/-0.041)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 3.1622776601683795, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.442 (+/-0.125)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 3.1622776601683795, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.504 (+/-0.080)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 3.1622776601683795, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.380 (+/-0.241)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 3.1622776601683795, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.345 (+/-0.182)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 10.0, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.348 (+/-0.254)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 10.0, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.305 (+/-0.361)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 10.0, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.369 (+/-0.164)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 10.0, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.269 (+/-0.115)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 10.0, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.410 (+/-0.071)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 10.0, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.447 (+/-0.066)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 10.0, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.478 (+/-0.204)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 10.0, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.346 (+/-0.053)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 10.0, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.442 (+/-0.125)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 10.0, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.504 (+/-0.080)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 10.0, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.380 (+/-0.241)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 10.0, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.345 (+/-0.182)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 31.622776601683793, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.283 (+/-0.227)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 31.622776601683793, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.235 (+/-0.235)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 31.622776601683793, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.347 (+/-0.239)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 31.622776601683793, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.216 (+/-0.123)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 31.622776601683793, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.411 (+/-0.064)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 31.622776601683793, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.452 (+/-0.045)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 31.622776601683793, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.434 (+/-0.080)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 31.622776601683793, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.348 (+/-0.055)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 31.622776601683793, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.442 (+/-0.125)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 31.622776601683793, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.504 (+/-0.080)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 31.622776601683793, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.380 (+/-0.241)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 31.622776601683793, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.345 (+/-0.182)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 100.0, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.397 (+/-0.202)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 100.0, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.440 (+/-0.142)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 100.0, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.290 (+/-0.204)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 100.0, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.283 (+/-0.122)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 100.0, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.411 (+/-0.064)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 100.0, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.452 (+/-0.045)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 100.0, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.308 (+/-0.301)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 100.0, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.353 (+/-0.041)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 100.0, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.442 (+/-0.125)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 100.0, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.504 (+/-0.080)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 100.0, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.380 (+/-0.241)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 100.0, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.345 (+/-0.182)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 316.22776601683796, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.319 (+/-0.151)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 316.22776601683796, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.319 (+/-0.134)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 316.22776601683796, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.319 (+/-0.151)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 316.22776601683796, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.267 (+/-0.094)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 316.22776601683796, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.411 (+/-0.064)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 316.22776601683796, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.451 (+/-0.049)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 316.22776601683796, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.467 (+/-0.112)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 316.22776601683796, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.353 (+/-0.041)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 316.22776601683796, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.442 (+/-0.125)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 316.22776601683796, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.504 (+/-0.080)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 316.22776601683796, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.380 (+/-0.241)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 316.22776601683796, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.345 (+/-0.182)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 1000.0, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.223 (+/-0.252)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 1000.0, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.155 (+/-0.271)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 1000.0, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.223 (+/-0.252)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 1000.0, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.292 (+/-0.115)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 1000.0, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.411 (+/-0.064)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 1000.0, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.452 (+/-0.045)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 1000.0, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.404 (+/-0.121)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 1000.0, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.352 (+/-0.038)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 1000.0, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.442 (+/-0.125)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 1000.0, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.504 (+/-0.080)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 1000.0, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.380 (+/-0.241)\n",
      "\n",
      "for {'alpha': 0.00031622776601683794, 'eta0': 1000.0, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.345 (+/-0.182)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 1e-05, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.343 (+/-0.053)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 1e-05, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.413 (+/-0.094)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 1e-05, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.495 (+/-0.095)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 1e-05, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.375 (+/-0.063)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 1e-05, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.344 (+/-0.056)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 1e-05, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.413 (+/-0.094)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 1e-05, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.444 (+/-0.141)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 1e-05, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.375 (+/-0.063)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 1e-05, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.430 (+/-0.053)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 1e-05, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.476 (+/-0.075)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 1e-05, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.441 (+/-0.175)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 1e-05, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.271 (+/-0.084)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.333 (+/-0.058)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.408 (+/-0.070)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.495 (+/-0.095)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.352 (+/-0.037)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.333 (+/-0.058)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.408 (+/-0.070)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.370 (+/-0.200)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.353 (+/-0.035)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.430 (+/-0.053)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.476 (+/-0.075)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.441 (+/-0.175)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.271 (+/-0.084)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 0.0001, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.318 (+/-0.040)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 0.0001, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.403 (+/-0.084)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 0.0001, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.477 (+/-0.036)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 0.0001, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.347 (+/-0.027)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 0.0001, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.316 (+/-0.040)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 0.0001, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.403 (+/-0.084)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 0.0001, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.356 (+/-0.244)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 0.0001, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.348 (+/-0.031)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 0.0001, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.430 (+/-0.053)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 0.0001, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.476 (+/-0.075)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 0.0001, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.441 (+/-0.175)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 0.0001, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.271 (+/-0.084)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 0.00031622776601683794, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.317 (+/-0.020)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 0.00031622776601683794, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.404 (+/-0.089)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 0.00031622776601683794, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.470 (+/-0.035)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 0.00031622776601683794, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.342 (+/-0.046)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 0.00031622776601683794, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.317 (+/-0.020)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 0.00031622776601683794, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.404 (+/-0.089)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 0.00031622776601683794, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.395 (+/-0.273)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 0.00031622776601683794, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.342 (+/-0.046)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 0.00031622776601683794, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.430 (+/-0.053)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 0.00031622776601683794, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.476 (+/-0.075)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 0.00031622776601683794, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.441 (+/-0.175)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 0.00031622776601683794, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.271 (+/-0.084)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 0.001, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.380 (+/-0.036)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 0.001, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.413 (+/-0.054)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 0.001, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.465 (+/-0.086)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 0.001, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.337 (+/-0.055)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 0.001, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.392 (+/-0.036)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 0.001, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.413 (+/-0.054)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 0.001, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.404 (+/-0.060)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 0.001, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.347 (+/-0.051)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 0.001, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.430 (+/-0.053)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 0.001, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.476 (+/-0.075)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 0.001, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.441 (+/-0.175)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 0.001, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.271 (+/-0.084)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 0.0031622776601683794, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.404 (+/-0.055)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 0.0031622776601683794, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.436 (+/-0.049)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 0.0031622776601683794, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.445 (+/-0.022)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 0.0031622776601683794, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.375 (+/-0.094)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 0.0031622776601683794, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.401 (+/-0.047)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 0.0031622776601683794, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.438 (+/-0.059)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 0.0031622776601683794, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.477 (+/-0.171)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 0.0031622776601683794, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.353 (+/-0.041)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 0.0031622776601683794, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.430 (+/-0.053)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 0.0031622776601683794, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.476 (+/-0.075)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 0.0031622776601683794, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.441 (+/-0.175)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 0.0031622776601683794, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.271 (+/-0.084)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.407 (+/-0.061)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.427 (+/-0.046)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.496 (+/-0.059)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.379 (+/-0.091)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 0.01, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.411 (+/-0.064)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 0.01, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.448 (+/-0.062)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 0.01, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.390 (+/-0.092)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 0.01, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.353 (+/-0.041)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.430 (+/-0.053)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.476 (+/-0.075)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.441 (+/-0.175)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.271 (+/-0.084)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 0.03162277660168379, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.433 (+/-0.049)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 0.03162277660168379, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.462 (+/-0.071)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 0.03162277660168379, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.409 (+/-0.272)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 0.03162277660168379, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.374 (+/-0.267)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 0.03162277660168379, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.411 (+/-0.064)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 0.03162277660168379, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.444 (+/-0.055)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 0.03162277660168379, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.359 (+/-0.186)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 0.03162277660168379, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.348 (+/-0.055)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 0.03162277660168379, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.430 (+/-0.053)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 0.03162277660168379, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.476 (+/-0.075)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 0.03162277660168379, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.441 (+/-0.175)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 0.03162277660168379, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.271 (+/-0.084)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.473 (+/-0.097)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.451 (+/-0.113)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.369 (+/-0.178)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.269 (+/-0.218)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 0.1, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.416 (+/-0.047)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 0.1, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.444 (+/-0.055)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 0.1, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.339 (+/-0.167)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 0.1, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.348 (+/-0.055)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.430 (+/-0.053)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.476 (+/-0.075)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.441 (+/-0.175)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.271 (+/-0.084)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 0.31622776601683794, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.414 (+/-0.167)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 0.31622776601683794, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.403 (+/-0.171)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 0.31622776601683794, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.322 (+/-0.080)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 0.31622776601683794, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.244 (+/-0.085)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 0.31622776601683794, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.406 (+/-0.053)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 0.31622776601683794, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.444 (+/-0.055)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 0.31622776601683794, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.414 (+/-0.104)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 0.31622776601683794, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.352 (+/-0.038)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 0.31622776601683794, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.430 (+/-0.053)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 0.31622776601683794, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.476 (+/-0.075)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 0.31622776601683794, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.441 (+/-0.175)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 0.31622776601683794, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.271 (+/-0.084)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 1.0, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.286 (+/-0.222)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 1.0, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.319 (+/-0.279)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 1.0, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.387 (+/-0.260)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 1.0, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.277 (+/-0.088)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 1.0, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.410 (+/-0.071)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 1.0, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.444 (+/-0.055)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 1.0, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.472 (+/-0.044)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 1.0, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.352 (+/-0.038)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 1.0, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.430 (+/-0.053)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 1.0, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.476 (+/-0.075)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 1.0, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.441 (+/-0.175)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 1.0, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.271 (+/-0.084)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 3.1622776601683795, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.317 (+/-0.222)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 3.1622776601683795, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.359 (+/-0.261)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 3.1622776601683795, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.369 (+/-0.164)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 3.1622776601683795, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.257 (+/-0.135)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 3.1622776601683795, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.406 (+/-0.053)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 3.1622776601683795, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.444 (+/-0.055)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 3.1622776601683795, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.499 (+/-0.151)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 3.1622776601683795, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.353 (+/-0.041)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 3.1622776601683795, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.430 (+/-0.053)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 3.1622776601683795, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.476 (+/-0.075)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 3.1622776601683795, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.441 (+/-0.175)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 3.1622776601683795, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.271 (+/-0.084)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 10.0, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.450 (+/-0.151)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 10.0, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.354 (+/-0.192)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 10.0, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.347 (+/-0.239)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 10.0, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.261 (+/-0.103)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 10.0, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.411 (+/-0.064)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 10.0, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.448 (+/-0.062)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 10.0, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.375 (+/-0.125)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 10.0, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.354 (+/-0.038)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 10.0, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.430 (+/-0.053)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 10.0, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.476 (+/-0.075)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 10.0, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.441 (+/-0.175)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 10.0, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.271 (+/-0.084)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 31.622776601683793, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.413 (+/-0.214)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 31.622776601683793, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.370 (+/-0.228)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 31.622776601683793, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.290 (+/-0.204)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 31.622776601683793, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.277 (+/-0.120)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 31.622776601683793, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.411 (+/-0.064)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 31.622776601683793, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.448 (+/-0.062)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 31.622776601683793, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.425 (+/-0.247)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 31.622776601683793, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.353 (+/-0.041)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 31.622776601683793, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.430 (+/-0.053)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 31.622776601683793, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.476 (+/-0.075)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 31.622776601683793, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.441 (+/-0.175)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 31.622776601683793, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.271 (+/-0.084)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 100.0, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.319 (+/-0.151)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 100.0, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.294 (+/-0.356)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 100.0, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.319 (+/-0.151)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 100.0, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.289 (+/-0.052)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 100.0, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.411 (+/-0.064)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 100.0, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.444 (+/-0.055)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 100.0, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.430 (+/-0.268)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 100.0, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.353 (+/-0.041)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 100.0, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.430 (+/-0.053)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 100.0, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.476 (+/-0.075)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 100.0, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.441 (+/-0.175)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 100.0, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.271 (+/-0.084)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 316.22776601683796, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.223 (+/-0.252)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 316.22776601683796, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.196 (+/-0.364)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 316.22776601683796, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.223 (+/-0.252)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 316.22776601683796, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.243 (+/-0.063)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 316.22776601683796, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.416 (+/-0.047)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 316.22776601683796, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.448 (+/-0.062)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 316.22776601683796, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.462 (+/-0.099)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 316.22776601683796, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.353 (+/-0.041)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 316.22776601683796, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.430 (+/-0.053)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 316.22776601683796, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.476 (+/-0.075)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 316.22776601683796, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.441 (+/-0.175)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 316.22776601683796, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.271 (+/-0.084)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 1000.0, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 1000.0, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.087 (+/-0.230)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 1000.0, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 1000.0, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.260 (+/-0.041)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 1000.0, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.411 (+/-0.064)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 1000.0, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.439 (+/-0.054)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 1000.0, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.455 (+/-0.204)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 1000.0, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.352 (+/-0.038)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 1000.0, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.430 (+/-0.053)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 1000.0, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.476 (+/-0.075)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 1000.0, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.441 (+/-0.175)\n",
      "\n",
      "for {'alpha': 0.001, 'eta0': 1000.0, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.271 (+/-0.084)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 1e-05, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.343 (+/-0.053)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 1e-05, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.413 (+/-0.094)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 1e-05, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.495 (+/-0.095)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 1e-05, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.375 (+/-0.063)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 1e-05, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.344 (+/-0.056)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 1e-05, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.413 (+/-0.094)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 1e-05, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.419 (+/-0.144)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 1e-05, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.376 (+/-0.064)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 1e-05, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.399 (+/-0.091)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 1e-05, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.451 (+/-0.060)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 1e-05, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.440 (+/-0.183)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 1e-05, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.387 (+/-0.041)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.333 (+/-0.058)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.399 (+/-0.049)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.477 (+/-0.036)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.352 (+/-0.037)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.333 (+/-0.058)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.399 (+/-0.049)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.356 (+/-0.244)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.353 (+/-0.035)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.399 (+/-0.091)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.451 (+/-0.060)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.440 (+/-0.183)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.387 (+/-0.041)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 0.0001, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.318 (+/-0.040)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 0.0001, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.393 (+/-0.105)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 0.0001, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.470 (+/-0.035)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 0.0001, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.347 (+/-0.027)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 0.0001, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.316 (+/-0.040)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 0.0001, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.393 (+/-0.105)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 0.0001, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.336 (+/-0.288)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 0.0001, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.348 (+/-0.031)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 0.0001, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.399 (+/-0.091)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 0.0001, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.451 (+/-0.060)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 0.0001, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.440 (+/-0.183)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 0.0001, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.387 (+/-0.041)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 0.00031622776601683794, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.317 (+/-0.020)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 0.00031622776601683794, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.401 (+/-0.091)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 0.00031622776601683794, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.465 (+/-0.086)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 0.00031622776601683794, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.342 (+/-0.046)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 0.00031622776601683794, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.317 (+/-0.020)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 0.00031622776601683794, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.401 (+/-0.091)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 0.00031622776601683794, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.369 (+/-0.224)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 0.00031622776601683794, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.337 (+/-0.055)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 0.00031622776601683794, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.399 (+/-0.091)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 0.00031622776601683794, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.451 (+/-0.060)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 0.00031622776601683794, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.440 (+/-0.183)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 0.00031622776601683794, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.387 (+/-0.041)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 0.001, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.380 (+/-0.036)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 0.001, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.409 (+/-0.053)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 0.001, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.445 (+/-0.022)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 0.001, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.337 (+/-0.055)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 0.001, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.392 (+/-0.036)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 0.001, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.409 (+/-0.053)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 0.001, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.409 (+/-0.194)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 0.001, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.342 (+/-0.046)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 0.001, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.399 (+/-0.091)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 0.001, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.451 (+/-0.060)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 0.001, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.440 (+/-0.183)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 0.001, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.387 (+/-0.041)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 0.0031622776601683794, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.401 (+/-0.069)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 0.0031622776601683794, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.427 (+/-0.039)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 0.0031622776601683794, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.482 (+/-0.064)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 0.0031622776601683794, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.375 (+/-0.094)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 0.0031622776601683794, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.401 (+/-0.047)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 0.0031622776601683794, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.427 (+/-0.039)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 0.0031622776601683794, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.455 (+/-0.145)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 0.0031622776601683794, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.353 (+/-0.041)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 0.0031622776601683794, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.399 (+/-0.091)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 0.0031622776601683794, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.451 (+/-0.060)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 0.0031622776601683794, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.440 (+/-0.183)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 0.0031622776601683794, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.387 (+/-0.041)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.401 (+/-0.086)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.414 (+/-0.038)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.474 (+/-0.102)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.380 (+/-0.092)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 0.01, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.411 (+/-0.064)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 0.01, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.435 (+/-0.052)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 0.01, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.377 (+/-0.081)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 0.01, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.353 (+/-0.041)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.399 (+/-0.091)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.451 (+/-0.060)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.440 (+/-0.183)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.387 (+/-0.041)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 0.03162277660168379, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.404 (+/-0.112)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 0.03162277660168379, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.441 (+/-0.064)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 0.03162277660168379, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.369 (+/-0.178)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 0.03162277660168379, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.370 (+/-0.264)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 0.03162277660168379, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.411 (+/-0.064)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 0.03162277660168379, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.435 (+/-0.052)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 0.03162277660168379, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.375 (+/-0.194)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 0.03162277660168379, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.348 (+/-0.055)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 0.03162277660168379, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.399 (+/-0.091)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 0.03162277660168379, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.451 (+/-0.060)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 0.03162277660168379, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.440 (+/-0.183)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 0.03162277660168379, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.387 (+/-0.041)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.426 (+/-0.107)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.439 (+/-0.107)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.322 (+/-0.080)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.257 (+/-0.233)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 0.1, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.406 (+/-0.053)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 0.1, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.445 (+/-0.056)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 0.1, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.449 (+/-0.096)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 0.1, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.348 (+/-0.055)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.399 (+/-0.091)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.451 (+/-0.060)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.440 (+/-0.183)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.387 (+/-0.041)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 0.31622776601683794, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.390 (+/-0.039)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 0.31622776601683794, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.408 (+/-0.278)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 0.31622776601683794, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.387 (+/-0.260)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 0.31622776601683794, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.236 (+/-0.158)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 0.31622776601683794, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.406 (+/-0.053)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 0.31622776601683794, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.436 (+/-0.052)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 0.31622776601683794, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.476 (+/-0.178)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 0.31622776601683794, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.353 (+/-0.041)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 0.31622776601683794, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.399 (+/-0.091)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 0.31622776601683794, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.451 (+/-0.060)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 0.31622776601683794, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.440 (+/-0.183)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 0.31622776601683794, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.387 (+/-0.041)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 1.0, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.385 (+/-0.232)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 1.0, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.226 (+/-0.252)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 1.0, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.369 (+/-0.164)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 1.0, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.222 (+/-0.120)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 1.0, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.401 (+/-0.047)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 1.0, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.436 (+/-0.052)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 1.0, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.431 (+/-0.161)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 1.0, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.353 (+/-0.041)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 1.0, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.399 (+/-0.091)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 1.0, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.451 (+/-0.060)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 1.0, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.440 (+/-0.183)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 1.0, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.387 (+/-0.041)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 3.1622776601683795, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.348 (+/-0.296)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 3.1622776601683795, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.267 (+/-0.315)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 3.1622776601683795, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.347 (+/-0.239)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 3.1622776601683795, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.289 (+/-0.107)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 3.1622776601683795, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.406 (+/-0.053)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 3.1622776601683795, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.435 (+/-0.052)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 3.1622776601683795, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.410 (+/-0.131)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 3.1622776601683795, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.354 (+/-0.038)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 3.1622776601683795, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.399 (+/-0.091)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 3.1622776601683795, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.451 (+/-0.060)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 3.1622776601683795, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.440 (+/-0.183)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 3.1622776601683795, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.387 (+/-0.041)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 10.0, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.372 (+/-0.276)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 10.0, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.360 (+/-0.251)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 10.0, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.290 (+/-0.204)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 10.0, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.258 (+/-0.223)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 10.0, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.406 (+/-0.053)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 10.0, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.444 (+/-0.055)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 10.0, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.438 (+/-0.093)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 10.0, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.349 (+/-0.054)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 10.0, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.399 (+/-0.091)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 10.0, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.451 (+/-0.060)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 10.0, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.440 (+/-0.183)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 10.0, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.387 (+/-0.041)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 31.622776601683793, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.319 (+/-0.151)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 31.622776601683793, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.325 (+/-0.155)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 31.622776601683793, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.319 (+/-0.151)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 31.622776601683793, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.223 (+/-0.147)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 31.622776601683793, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.411 (+/-0.064)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 31.622776601683793, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.445 (+/-0.056)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 31.622776601683793, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.367 (+/-0.185)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 31.622776601683793, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.353 (+/-0.041)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 31.622776601683793, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.399 (+/-0.091)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 31.622776601683793, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.451 (+/-0.060)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 31.622776601683793, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.440 (+/-0.183)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 31.622776601683793, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.387 (+/-0.041)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 100.0, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.241 (+/-0.284)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 100.0, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.194 (+/-0.344)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 100.0, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.223 (+/-0.252)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 100.0, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.258 (+/-0.122)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 100.0, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.406 (+/-0.053)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 100.0, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.435 (+/-0.052)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 100.0, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.410 (+/-0.210)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 100.0, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.349 (+/-0.054)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 100.0, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.399 (+/-0.091)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 100.0, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.451 (+/-0.060)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 100.0, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.440 (+/-0.183)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 100.0, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.387 (+/-0.041)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 316.22776601683796, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 316.22776601683796, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.056 (+/-0.224)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 316.22776601683796, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.085 (+/-0.223)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 316.22776601683796, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.255 (+/-0.060)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 316.22776601683796, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.401 (+/-0.054)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 316.22776601683796, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.435 (+/-0.052)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 316.22776601683796, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.443 (+/-0.219)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 316.22776601683796, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.354 (+/-0.038)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 316.22776601683796, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.399 (+/-0.091)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 316.22776601683796, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.451 (+/-0.060)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 316.22776601683796, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.440 (+/-0.183)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 316.22776601683796, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.387 (+/-0.041)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 1000.0, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 1000.0, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.087 (+/-0.230)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 1000.0, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 1000.0, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.260 (+/-0.041)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 1000.0, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.401 (+/-0.054)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 1000.0, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.436 (+/-0.053)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 1000.0, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.324 (+/-0.178)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 1000.0, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.348 (+/-0.055)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 1000.0, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.399 (+/-0.091)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 1000.0, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.451 (+/-0.060)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 1000.0, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.440 (+/-0.183)\n",
      "\n",
      "for {'alpha': 0.0031622776601683794, 'eta0': 1000.0, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.387 (+/-0.041)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 1e-05, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.345 (+/-0.055)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 1e-05, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.413 (+/-0.094)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 1e-05, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.477 (+/-0.036)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 1e-05, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.375 (+/-0.063)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 1e-05, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.345 (+/-0.055)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 1e-05, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.413 (+/-0.094)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 1e-05, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.488 (+/-0.071)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 1e-05, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.373 (+/-0.061)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 1e-05, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.386 (+/-0.077)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 1e-05, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.414 (+/-0.031)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 1e-05, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.408 (+/-0.252)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 1e-05, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.365 (+/-0.080)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.334 (+/-0.060)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.379 (+/-0.066)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.470 (+/-0.035)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.354 (+/-0.038)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.334 (+/-0.060)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.385 (+/-0.067)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.336 (+/-0.288)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.354 (+/-0.038)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.386 (+/-0.077)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.414 (+/-0.031)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.408 (+/-0.252)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.365 (+/-0.080)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 0.0001, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.318 (+/-0.040)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 0.0001, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.380 (+/-0.085)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 0.0001, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.465 (+/-0.086)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 0.0001, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.342 (+/-0.046)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 0.0001, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.318 (+/-0.040)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 0.0001, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.385 (+/-0.099)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 0.0001, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.305 (+/-0.227)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 0.0001, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.342 (+/-0.046)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 0.0001, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.386 (+/-0.077)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 0.0001, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.414 (+/-0.031)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 0.0001, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.408 (+/-0.252)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 0.0001, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.365 (+/-0.080)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 0.00031622776601683794, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.313 (+/-0.042)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 0.00031622776601683794, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.397 (+/-0.081)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 0.00031622776601683794, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.445 (+/-0.022)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 0.00031622776601683794, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.337 (+/-0.055)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 0.00031622776601683794, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.317 (+/-0.020)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 0.00031622776601683794, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.397 (+/-0.081)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 0.00031622776601683794, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.374 (+/-0.242)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 0.00031622776601683794, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.337 (+/-0.055)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 0.00031622776601683794, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.386 (+/-0.077)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 0.00031622776601683794, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.414 (+/-0.031)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 0.00031622776601683794, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.408 (+/-0.252)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 0.00031622776601683794, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.365 (+/-0.080)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 0.001, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.361 (+/-0.009)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 0.001, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.397 (+/-0.078)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 0.001, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.482 (+/-0.064)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 0.001, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.337 (+/-0.055)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 0.001, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.377 (+/-0.045)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 0.001, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.393 (+/-0.067)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 0.001, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.400 (+/-0.182)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 0.001, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.337 (+/-0.055)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 0.001, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.386 (+/-0.077)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 0.001, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.414 (+/-0.031)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 0.001, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.408 (+/-0.252)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 0.001, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.365 (+/-0.080)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 0.0031622776601683794, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.382 (+/-0.064)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 0.0031622776601683794, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.401 (+/-0.056)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 0.0031622776601683794, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.474 (+/-0.102)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 0.0031622776601683794, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.370 (+/-0.092)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 0.0031622776601683794, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.397 (+/-0.042)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 0.0031622776601683794, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.401 (+/-0.056)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 0.0031622776601683794, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.501 (+/-0.092)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 0.0031622776601683794, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.354 (+/-0.038)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 0.0031622776601683794, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.386 (+/-0.077)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 0.0031622776601683794, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.414 (+/-0.031)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 0.0031622776601683794, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.408 (+/-0.252)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 0.0031622776601683794, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.365 (+/-0.080)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.404 (+/-0.052)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.413 (+/-0.050)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.408 (+/-0.193)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.377 (+/-0.085)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 0.01, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.397 (+/-0.042)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 0.01, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.401 (+/-0.056)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 0.01, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.373 (+/-0.086)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 0.01, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.354 (+/-0.038)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.386 (+/-0.077)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.414 (+/-0.031)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.408 (+/-0.252)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.365 (+/-0.080)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 0.03162277660168379, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.391 (+/-0.054)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 0.03162277660168379, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.424 (+/-0.081)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 0.03162277660168379, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.322 (+/-0.080)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 0.03162277660168379, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.370 (+/-0.264)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 0.03162277660168379, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.402 (+/-0.042)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 0.03162277660168379, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.406 (+/-0.041)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 0.03162277660168379, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.425 (+/-0.238)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 0.03162277660168379, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.343 (+/-0.064)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 0.03162277660168379, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.386 (+/-0.077)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 0.03162277660168379, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.414 (+/-0.031)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 0.03162277660168379, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.408 (+/-0.252)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 0.03162277660168379, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.365 (+/-0.080)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.399 (+/-0.100)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.401 (+/-0.107)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.387 (+/-0.260)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.275 (+/-0.224)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 0.1, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.397 (+/-0.042)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 0.1, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.410 (+/-0.039)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 0.1, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.368 (+/-0.236)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 0.1, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.342 (+/-0.061)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.386 (+/-0.077)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.414 (+/-0.031)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.408 (+/-0.252)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.365 (+/-0.080)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 0.31622776601683794, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.409 (+/-0.159)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 0.31622776601683794, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.388 (+/-0.271)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 0.31622776601683794, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.369 (+/-0.164)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 0.31622776601683794, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.248 (+/-0.038)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 0.31622776601683794, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.397 (+/-0.042)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 0.31622776601683794, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.410 (+/-0.039)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 0.31622776601683794, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.378 (+/-0.236)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 0.31622776601683794, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.349 (+/-0.054)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 0.31622776601683794, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.386 (+/-0.077)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 0.31622776601683794, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.414 (+/-0.031)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 0.31622776601683794, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.408 (+/-0.252)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 0.31622776601683794, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.365 (+/-0.080)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 1.0, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.451 (+/-0.278)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 1.0, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.354 (+/-0.257)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 1.0, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.347 (+/-0.239)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 1.0, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.217 (+/-0.094)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 1.0, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.397 (+/-0.042)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 1.0, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.406 (+/-0.041)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 1.0, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.458 (+/-0.088)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 1.0, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.348 (+/-0.055)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 1.0, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.386 (+/-0.077)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 1.0, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.414 (+/-0.031)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 1.0, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.408 (+/-0.252)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 1.0, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.365 (+/-0.080)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 3.1622776601683795, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.328 (+/-0.188)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 3.1622776601683795, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.424 (+/-0.084)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 3.1622776601683795, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.290 (+/-0.204)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 3.1622776601683795, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.223 (+/-0.235)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 3.1622776601683795, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.397 (+/-0.042)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 3.1622776601683795, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.401 (+/-0.056)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 3.1622776601683795, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.374 (+/-0.178)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 3.1622776601683795, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.349 (+/-0.054)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 3.1622776601683795, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.386 (+/-0.077)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 3.1622776601683795, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.414 (+/-0.031)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 3.1622776601683795, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.408 (+/-0.252)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 3.1622776601683795, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.365 (+/-0.080)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 10.0, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.315 (+/-0.143)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 10.0, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.340 (+/-0.219)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 10.0, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.319 (+/-0.151)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 10.0, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.209 (+/-0.098)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 10.0, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.402 (+/-0.042)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 10.0, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.405 (+/-0.057)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 10.0, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.459 (+/-0.246)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 10.0, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.349 (+/-0.054)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 10.0, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.386 (+/-0.077)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 10.0, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.414 (+/-0.031)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 10.0, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.408 (+/-0.252)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 10.0, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.365 (+/-0.080)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 31.622776601683793, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.241 (+/-0.284)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 31.622776601683793, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.188 (+/-0.227)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 31.622776601683793, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.223 (+/-0.252)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 31.622776601683793, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.306 (+/-0.090)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 31.622776601683793, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.402 (+/-0.042)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 31.622776601683793, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.405 (+/-0.066)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 31.622776601683793, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.336 (+/-0.318)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 31.622776601683793, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.354 (+/-0.038)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 31.622776601683793, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.386 (+/-0.077)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 31.622776601683793, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.414 (+/-0.031)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 31.622776601683793, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.408 (+/-0.252)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 31.622776601683793, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.365 (+/-0.080)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 100.0, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 100.0, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.056 (+/-0.225)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 100.0, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 100.0, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.267 (+/-0.050)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 100.0, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.402 (+/-0.042)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 100.0, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.405 (+/-0.066)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 100.0, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.418 (+/-0.093)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 100.0, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.354 (+/-0.038)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 100.0, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.386 (+/-0.077)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 100.0, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.414 (+/-0.031)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 100.0, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.408 (+/-0.252)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 100.0, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.365 (+/-0.080)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 316.22776601683796, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 316.22776601683796, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.056 (+/-0.224)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 316.22776601683796, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.085 (+/-0.223)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 316.22776601683796, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.255 (+/-0.060)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 316.22776601683796, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.397 (+/-0.042)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 316.22776601683796, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.410 (+/-0.052)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 316.22776601683796, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.391 (+/-0.162)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 316.22776601683796, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.349 (+/-0.054)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 316.22776601683796, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.386 (+/-0.077)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 316.22776601683796, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.414 (+/-0.031)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 316.22776601683796, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.408 (+/-0.252)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 316.22776601683796, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.365 (+/-0.080)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 1000.0, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 1000.0, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.087 (+/-0.230)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 1000.0, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 1000.0, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.260 (+/-0.041)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 1000.0, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.397 (+/-0.042)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 1000.0, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.401 (+/-0.056)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 1000.0, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.462 (+/-0.109)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 1000.0, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.354 (+/-0.038)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 1000.0, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.386 (+/-0.077)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 1000.0, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.414 (+/-0.031)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 1000.0, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.408 (+/-0.252)\n",
      "\n",
      "for {'alpha': 0.01, 'eta0': 1000.0, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.365 (+/-0.080)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 1e-05, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.346 (+/-0.054)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 1e-05, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.395 (+/-0.055)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 1e-05, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.470 (+/-0.035)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 1e-05, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.363 (+/-0.058)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 1e-05, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.346 (+/-0.054)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 1e-05, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.395 (+/-0.055)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 1e-05, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.399 (+/-0.107)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 1e-05, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.358 (+/-0.053)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 1e-05, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.372 (+/-0.056)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 1e-05, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.377 (+/-0.055)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 1e-05, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.415 (+/-0.142)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 1e-05, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.359 (+/-0.068)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.323 (+/-0.037)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.374 (+/-0.062)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.465 (+/-0.086)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.356 (+/-0.036)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.323 (+/-0.037)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.374 (+/-0.062)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.305 (+/-0.227)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.357 (+/-0.034)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.372 (+/-0.056)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.377 (+/-0.055)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.415 (+/-0.142)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.359 (+/-0.068)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 0.0001, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.319 (+/-0.041)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 0.0001, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.365 (+/-0.053)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 0.0001, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.445 (+/-0.022)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 0.0001, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.344 (+/-0.050)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 0.0001, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.314 (+/-0.027)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 0.0001, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.365 (+/-0.053)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 0.0001, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.377 (+/-0.256)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 0.0001, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.338 (+/-0.059)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 0.0001, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.372 (+/-0.056)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 0.0001, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.377 (+/-0.055)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 0.0001, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.415 (+/-0.142)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 0.0001, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.359 (+/-0.068)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 0.00031622776601683794, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.316 (+/-0.046)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 0.00031622776601683794, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.363 (+/-0.045)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 0.00031622776601683794, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.482 (+/-0.064)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 0.00031622776601683794, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.338 (+/-0.059)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 0.00031622776601683794, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.316 (+/-0.046)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 0.00031622776601683794, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.363 (+/-0.045)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 0.00031622776601683794, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.371 (+/-0.131)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 0.00031622776601683794, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.338 (+/-0.059)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 0.00031622776601683794, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.372 (+/-0.056)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 0.00031622776601683794, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.377 (+/-0.055)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 0.00031622776601683794, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.415 (+/-0.142)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 0.00031622776601683794, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.359 (+/-0.068)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 0.001, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.342 (+/-0.039)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 0.001, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.371 (+/-0.046)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 0.001, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.474 (+/-0.102)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 0.001, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.337 (+/-0.055)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 0.001, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.347 (+/-0.041)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 0.001, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.371 (+/-0.046)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 0.001, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.362 (+/-0.177)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 0.001, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.338 (+/-0.059)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 0.001, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.372 (+/-0.056)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 0.001, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.377 (+/-0.055)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 0.001, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.415 (+/-0.142)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 0.001, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.359 (+/-0.068)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 0.0031622776601683794, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.336 (+/-0.101)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 0.0031622776601683794, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.377 (+/-0.055)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 0.0031622776601683794, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.442 (+/-0.026)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 0.0031622776601683794, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.357 (+/-0.055)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 0.0031622776601683794, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.373 (+/-0.042)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 0.0031622776601683794, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.374 (+/-0.050)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 0.0031622776601683794, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.461 (+/-0.116)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 0.0031622776601683794, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.338 (+/-0.059)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 0.0031622776601683794, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.372 (+/-0.056)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 0.0031622776601683794, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.377 (+/-0.055)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 0.0031622776601683794, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.415 (+/-0.142)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 0.0031622776601683794, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.359 (+/-0.068)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.363 (+/-0.080)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.370 (+/-0.054)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.366 (+/-0.132)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.366 (+/-0.095)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 0.01, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.373 (+/-0.042)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 0.01, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.376 (+/-0.052)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 0.01, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.372 (+/-0.091)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 0.01, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.338 (+/-0.059)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.372 (+/-0.056)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.377 (+/-0.055)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.415 (+/-0.142)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.359 (+/-0.068)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 0.03162277660168379, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.359 (+/-0.099)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 0.03162277660168379, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.374 (+/-0.047)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 0.03162277660168379, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.348 (+/-0.228)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 0.03162277660168379, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.332 (+/-0.227)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 0.03162277660168379, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.373 (+/-0.042)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 0.03162277660168379, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.374 (+/-0.050)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 0.03162277660168379, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.334 (+/-0.271)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 0.03162277660168379, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.338 (+/-0.059)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 0.03162277660168379, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.372 (+/-0.056)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 0.03162277660168379, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.377 (+/-0.055)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 0.03162277660168379, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.415 (+/-0.142)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 0.03162277660168379, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.359 (+/-0.068)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.333 (+/-0.220)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.343 (+/-0.146)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.369 (+/-0.164)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.247 (+/-0.127)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 0.1, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.373 (+/-0.042)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 0.1, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.374 (+/-0.050)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 0.1, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.435 (+/-0.384)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 0.1, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.338 (+/-0.059)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.372 (+/-0.056)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.377 (+/-0.055)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.415 (+/-0.142)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.359 (+/-0.068)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 0.31622776601683794, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.272 (+/-0.250)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 0.31622776601683794, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.301 (+/-0.332)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 0.31622776601683794, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.347 (+/-0.239)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 0.31622776601683794, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.254 (+/-0.054)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 0.31622776601683794, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.373 (+/-0.042)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 0.31622776601683794, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.369 (+/-0.046)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 0.31622776601683794, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.452 (+/-0.163)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 0.31622776601683794, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.338 (+/-0.059)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 0.31622776601683794, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.372 (+/-0.056)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 0.31622776601683794, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.377 (+/-0.055)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 0.31622776601683794, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.415 (+/-0.142)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 0.31622776601683794, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.359 (+/-0.068)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 1.0, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.403 (+/-0.243)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 1.0, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.289 (+/-0.347)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 1.0, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.290 (+/-0.204)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 1.0, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.200 (+/-0.179)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 1.0, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.374 (+/-0.043)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 1.0, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.376 (+/-0.050)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 1.0, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.448 (+/-0.070)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 1.0, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.338 (+/-0.059)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 1.0, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.372 (+/-0.056)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 1.0, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.377 (+/-0.055)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 1.0, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.415 (+/-0.142)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 1.0, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.359 (+/-0.068)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 3.1622776601683795, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.320 (+/-0.165)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 3.1622776601683795, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.328 (+/-0.160)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 3.1622776601683795, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.319 (+/-0.151)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 3.1622776601683795, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.221 (+/-0.061)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 3.1622776601683795, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.378 (+/-0.041)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 3.1622776601683795, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.374 (+/-0.050)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 3.1622776601683795, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.407 (+/-0.175)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 3.1622776601683795, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.338 (+/-0.059)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 3.1622776601683795, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.372 (+/-0.056)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 3.1622776601683795, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.377 (+/-0.055)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 3.1622776601683795, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.415 (+/-0.142)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 3.1622776601683795, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.359 (+/-0.068)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 10.0, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.270 (+/-0.334)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 10.0, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.226 (+/-0.249)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 10.0, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.223 (+/-0.252)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 10.0, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.238 (+/-0.100)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 10.0, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.373 (+/-0.042)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 10.0, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.369 (+/-0.046)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 10.0, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.425 (+/-0.135)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 10.0, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.338 (+/-0.059)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 10.0, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.372 (+/-0.056)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 10.0, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.377 (+/-0.055)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 10.0, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.415 (+/-0.142)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 10.0, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.359 (+/-0.068)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 31.622776601683793, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 31.622776601683793, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.059 (+/-0.236)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 31.622776601683793, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 31.622776601683793, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.260 (+/-0.165)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 31.622776601683793, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.373 (+/-0.042)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 31.622776601683793, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.374 (+/-0.050)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 31.622776601683793, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.381 (+/-0.282)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 31.622776601683793, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.338 (+/-0.059)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 31.622776601683793, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.372 (+/-0.056)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 31.622776601683793, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.377 (+/-0.055)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 31.622776601683793, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.415 (+/-0.142)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 31.622776601683793, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.359 (+/-0.068)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 100.0, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 100.0, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.056 (+/-0.225)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 100.0, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 100.0, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.267 (+/-0.050)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 100.0, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.372 (+/-0.042)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 100.0, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.374 (+/-0.050)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 100.0, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.368 (+/-0.183)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 100.0, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.338 (+/-0.059)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 100.0, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.372 (+/-0.056)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 100.0, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.377 (+/-0.055)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 100.0, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.415 (+/-0.142)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 100.0, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.359 (+/-0.068)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 316.22776601683796, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 316.22776601683796, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.056 (+/-0.224)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 316.22776601683796, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.085 (+/-0.223)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 316.22776601683796, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.255 (+/-0.060)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 316.22776601683796, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.373 (+/-0.042)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 316.22776601683796, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.369 (+/-0.046)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 316.22776601683796, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.359 (+/-0.143)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 316.22776601683796, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.338 (+/-0.059)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 316.22776601683796, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.372 (+/-0.056)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 316.22776601683796, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.377 (+/-0.055)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 316.22776601683796, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.415 (+/-0.142)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 316.22776601683796, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.359 (+/-0.068)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 1000.0, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 1000.0, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.087 (+/-0.230)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 1000.0, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 1000.0, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.260 (+/-0.041)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 1000.0, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.373 (+/-0.042)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 1000.0, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.374 (+/-0.050)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 1000.0, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.324 (+/-0.201)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 1000.0, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.338 (+/-0.059)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 1000.0, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.372 (+/-0.056)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 1000.0, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.377 (+/-0.055)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 1000.0, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.415 (+/-0.142)\n",
      "\n",
      "for {'alpha': 0.03162277660168379, 'eta0': 1000.0, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.359 (+/-0.068)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 1e-05, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.333 (+/-0.058)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 1e-05, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.388 (+/-0.033)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 1e-05, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.465 (+/-0.086)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 1e-05, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.352 (+/-0.035)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 1e-05, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.333 (+/-0.058)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 1e-05, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.390 (+/-0.033)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 1e-05, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.440 (+/-0.031)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 1e-05, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.352 (+/-0.035)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 1e-05, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.287 (+/-0.079)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 1e-05, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.280 (+/-0.079)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 1e-05, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.378 (+/-0.193)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 1e-05, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.356 (+/-0.078)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.318 (+/-0.040)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.347 (+/-0.025)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.445 (+/-0.022)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.339 (+/-0.050)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.320 (+/-0.042)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.347 (+/-0.025)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.377 (+/-0.256)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.335 (+/-0.038)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.287 (+/-0.079)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.280 (+/-0.079)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.378 (+/-0.193)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.356 (+/-0.078)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 0.0001, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.299 (+/-0.068)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 0.0001, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.317 (+/-0.052)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 0.0001, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.482 (+/-0.064)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 0.0001, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.333 (+/-0.046)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 0.0001, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.287 (+/-0.060)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 0.0001, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.317 (+/-0.052)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 0.0001, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.393 (+/-0.161)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 0.0001, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.333 (+/-0.046)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 0.0001, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.287 (+/-0.079)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 0.0001, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.280 (+/-0.079)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 0.0001, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.378 (+/-0.193)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 0.0001, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.356 (+/-0.078)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 0.00031622776601683794, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.263 (+/-0.090)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 0.00031622776601683794, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.297 (+/-0.055)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 0.00031622776601683794, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.474 (+/-0.102)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 0.00031622776601683794, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.330 (+/-0.042)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 0.00031622776601683794, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.263 (+/-0.090)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 0.00031622776601683794, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.297 (+/-0.055)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 0.00031622776601683794, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.384 (+/-0.087)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 0.00031622776601683794, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.330 (+/-0.042)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 0.00031622776601683794, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.287 (+/-0.079)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 0.00031622776601683794, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.280 (+/-0.079)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 0.00031622776601683794, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.378 (+/-0.193)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 0.00031622776601683794, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.356 (+/-0.078)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 0.001, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.263 (+/-0.090)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 0.001, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.292 (+/-0.081)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 0.001, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.442 (+/-0.026)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 0.001, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.330 (+/-0.042)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 0.001, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.269 (+/-0.079)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 0.001, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.292 (+/-0.081)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 0.001, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.444 (+/-0.136)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 0.001, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.328 (+/-0.040)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 0.001, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.287 (+/-0.079)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 0.001, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.280 (+/-0.079)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 0.001, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.378 (+/-0.193)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 0.001, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.356 (+/-0.078)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 0.0031622776601683794, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.281 (+/-0.079)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 0.0031622776601683794, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.274 (+/-0.085)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 0.0031622776601683794, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.428 (+/-0.081)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 0.0031622776601683794, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.348 (+/-0.052)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 0.0031622776601683794, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.281 (+/-0.068)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 0.0031622776601683794, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.280 (+/-0.079)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 0.0031622776601683794, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.483 (+/-0.167)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 0.0031622776601683794, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.328 (+/-0.040)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 0.0031622776601683794, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.287 (+/-0.079)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 0.0031622776601683794, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.280 (+/-0.079)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 0.0031622776601683794, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.378 (+/-0.193)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 0.0031622776601683794, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.356 (+/-0.078)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.310 (+/-0.056)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.280 (+/-0.079)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.434 (+/-0.121)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.345 (+/-0.070)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 0.01, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.281 (+/-0.068)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 0.01, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.280 (+/-0.079)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 0.01, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.341 (+/-0.076)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 0.01, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.328 (+/-0.040)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.287 (+/-0.079)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.280 (+/-0.079)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.378 (+/-0.193)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.356 (+/-0.078)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 0.03162277660168379, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.321 (+/-0.165)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 0.03162277660168379, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.271 (+/-0.109)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 0.03162277660168379, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.415 (+/-0.035)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 0.03162277660168379, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.334 (+/-0.316)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 0.03162277660168379, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.281 (+/-0.068)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 0.03162277660168379, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.280 (+/-0.079)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 0.03162277660168379, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.439 (+/-0.115)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 0.03162277660168379, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.328 (+/-0.040)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 0.03162277660168379, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.287 (+/-0.079)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 0.03162277660168379, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.280 (+/-0.079)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 0.03162277660168379, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.378 (+/-0.193)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 0.03162277660168379, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.356 (+/-0.078)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.269 (+/-0.241)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.278 (+/-0.210)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.347 (+/-0.239)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.234 (+/-0.230)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 0.1, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.281 (+/-0.068)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 0.1, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.280 (+/-0.079)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 0.1, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.428 (+/-0.167)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 0.1, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.328 (+/-0.040)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.287 (+/-0.079)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.280 (+/-0.079)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.378 (+/-0.193)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.356 (+/-0.078)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 0.31622776601683794, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.374 (+/-0.320)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 0.31622776601683794, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.337 (+/-0.273)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 0.31622776601683794, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.290 (+/-0.204)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 0.31622776601683794, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.231 (+/-0.084)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 0.31622776601683794, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.281 (+/-0.068)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 0.31622776601683794, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.274 (+/-0.085)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 0.31622776601683794, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.416 (+/-0.199)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 0.31622776601683794, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.328 (+/-0.040)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 0.31622776601683794, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.287 (+/-0.079)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 0.31622776601683794, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.280 (+/-0.079)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 0.31622776601683794, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.378 (+/-0.193)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 0.31622776601683794, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.356 (+/-0.078)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 1.0, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.295 (+/-0.217)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 1.0, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.361 (+/-0.143)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 1.0, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.319 (+/-0.151)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 1.0, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.235 (+/-0.097)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 1.0, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.281 (+/-0.068)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 1.0, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.280 (+/-0.079)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 1.0, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.473 (+/-0.227)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 1.0, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.328 (+/-0.040)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 1.0, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.287 (+/-0.079)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 1.0, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.280 (+/-0.079)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 1.0, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.378 (+/-0.193)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 1.0, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.356 (+/-0.078)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 3.1622776601683795, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.158 (+/-0.278)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 3.1622776601683795, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.211 (+/-0.401)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 3.1622776601683795, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.223 (+/-0.252)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 3.1622776601683795, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.235 (+/-0.200)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 3.1622776601683795, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.281 (+/-0.068)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 3.1622776601683795, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.280 (+/-0.079)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 3.1622776601683795, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.404 (+/-0.091)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 3.1622776601683795, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.328 (+/-0.040)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 3.1622776601683795, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.287 (+/-0.079)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 3.1622776601683795, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.280 (+/-0.079)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 3.1622776601683795, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.378 (+/-0.193)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 3.1622776601683795, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.356 (+/-0.078)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 10.0, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 10.0, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.056 (+/-0.224)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 10.0, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 10.0, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.266 (+/-0.060)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 10.0, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.275 (+/-0.064)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 10.0, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.286 (+/-0.060)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 10.0, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.431 (+/-0.118)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 10.0, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.330 (+/-0.042)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 10.0, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.287 (+/-0.079)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 10.0, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.280 (+/-0.079)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 10.0, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.378 (+/-0.193)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 10.0, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.356 (+/-0.078)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 31.622776601683793, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 31.622776601683793, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.059 (+/-0.236)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 31.622776601683793, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.089 (+/-0.237)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 31.622776601683793, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.192 (+/-0.110)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 31.622776601683793, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.281 (+/-0.068)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 31.622776601683793, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.280 (+/-0.079)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 31.622776601683793, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.329 (+/-0.135)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 31.622776601683793, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.328 (+/-0.040)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 31.622776601683793, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.287 (+/-0.079)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 31.622776601683793, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.280 (+/-0.079)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 31.622776601683793, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.378 (+/-0.193)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 31.622776601683793, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.356 (+/-0.078)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 100.0, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 100.0, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.056 (+/-0.225)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 100.0, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 100.0, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.267 (+/-0.050)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 100.0, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.281 (+/-0.068)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 100.0, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.280 (+/-0.079)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 100.0, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.380 (+/-0.252)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 100.0, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.328 (+/-0.040)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 100.0, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.287 (+/-0.079)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 100.0, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.280 (+/-0.079)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 100.0, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.378 (+/-0.193)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 100.0, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.356 (+/-0.078)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 316.22776601683796, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 316.22776601683796, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.056 (+/-0.224)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 316.22776601683796, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.085 (+/-0.223)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 316.22776601683796, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.255 (+/-0.060)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 316.22776601683796, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.281 (+/-0.068)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 316.22776601683796, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.280 (+/-0.079)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 316.22776601683796, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.448 (+/-0.169)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 316.22776601683796, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.328 (+/-0.040)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 316.22776601683796, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.287 (+/-0.079)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 316.22776601683796, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.280 (+/-0.079)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 316.22776601683796, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.378 (+/-0.193)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 316.22776601683796, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.356 (+/-0.078)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 1000.0, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 1000.0, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.087 (+/-0.230)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 1000.0, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 1000.0, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.260 (+/-0.041)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 1000.0, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.281 (+/-0.068)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 1000.0, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.280 (+/-0.079)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 1000.0, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.465 (+/-0.105)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 1000.0, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.328 (+/-0.040)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 1000.0, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.287 (+/-0.079)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 1000.0, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.280 (+/-0.079)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 1000.0, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.378 (+/-0.193)\n",
      "\n",
      "for {'alpha': 0.1, 'eta0': 1000.0, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.356 (+/-0.078)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 1e-05, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.315 (+/-0.025)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 1e-05, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.348 (+/-0.032)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 1e-05, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.445 (+/-0.022)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 1e-05, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.348 (+/-0.024)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 1e-05, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.315 (+/-0.025)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 1e-05, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.343 (+/-0.025)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 1e-05, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.430 (+/-0.230)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 1e-05, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.348 (+/-0.024)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 1e-05, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.155 (+/-0.117)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 1e-05, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.147 (+/-0.133)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 1e-05, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.378 (+/-0.269)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 1e-05, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.292 (+/-0.061)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.281 (+/-0.057)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.292 (+/-0.061)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.482 (+/-0.064)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.318 (+/-0.063)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.275 (+/-0.064)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.292 (+/-0.061)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.393 (+/-0.161)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.319 (+/-0.062)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.155 (+/-0.117)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.147 (+/-0.133)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.378 (+/-0.269)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.292 (+/-0.061)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 0.0001, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.246 (+/-0.074)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 0.0001, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.245 (+/-0.087)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 0.0001, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.474 (+/-0.102)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 0.0001, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.303 (+/-0.033)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 0.0001, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.233 (+/-0.098)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 0.0001, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.239 (+/-0.100)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 0.0001, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.386 (+/-0.190)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 0.0001, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.303 (+/-0.033)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 0.0001, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.155 (+/-0.117)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 0.0001, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.147 (+/-0.133)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 0.0001, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.378 (+/-0.269)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 0.0001, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.292 (+/-0.061)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 0.00031622776601683794, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.187 (+/-0.151)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 0.00031622776601683794, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.188 (+/-0.126)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 0.00031622776601683794, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.442 (+/-0.026)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 0.00031622776601683794, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.298 (+/-0.057)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 0.00031622776601683794, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.181 (+/-0.138)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 0.00031622776601683794, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.188 (+/-0.126)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 0.00031622776601683794, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.368 (+/-0.086)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 0.00031622776601683794, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.298 (+/-0.057)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 0.00031622776601683794, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.155 (+/-0.117)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 0.00031622776601683794, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.147 (+/-0.133)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 0.00031622776601683794, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.378 (+/-0.269)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 0.00031622776601683794, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.292 (+/-0.061)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 0.001, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.161 (+/-0.126)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 0.001, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.160 (+/-0.163)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 0.001, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.428 (+/-0.081)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 0.001, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.298 (+/-0.057)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 0.001, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.155 (+/-0.117)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 0.001, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.153 (+/-0.147)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 0.001, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.414 (+/-0.206)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 0.001, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.298 (+/-0.057)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 0.001, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.155 (+/-0.117)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 0.001, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.147 (+/-0.133)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 0.001, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.378 (+/-0.269)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 0.001, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.292 (+/-0.061)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 0.0031622776601683794, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.161 (+/-0.141)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 0.0031622776601683794, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.145 (+/-0.177)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 0.0031622776601683794, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.421 (+/-0.172)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 0.0031622776601683794, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.295 (+/-0.070)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 0.0031622776601683794, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.148 (+/-0.114)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 0.0031622776601683794, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.153 (+/-0.147)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 0.0031622776601683794, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.495 (+/-0.198)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 0.0031622776601683794, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.292 (+/-0.081)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 0.0031622776601683794, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.155 (+/-0.117)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 0.0031622776601683794, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.147 (+/-0.133)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 0.0031622776601683794, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.378 (+/-0.269)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 0.0031622776601683794, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.292 (+/-0.061)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.176 (+/-0.078)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.140 (+/-0.131)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.371 (+/-0.205)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.294 (+/-0.062)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 0.01, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.155 (+/-0.117)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 0.01, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.153 (+/-0.147)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 0.01, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.410 (+/-0.109)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 0.01, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.292 (+/-0.061)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.155 (+/-0.117)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.147 (+/-0.133)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.378 (+/-0.269)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.292 (+/-0.061)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 0.03162277660168379, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.238 (+/-0.132)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 0.03162277660168379, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.126 (+/-0.116)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 0.03162277660168379, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.347 (+/-0.239)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 0.03162277660168379, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.333 (+/-0.352)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 0.03162277660168379, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.148 (+/-0.114)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 0.03162277660168379, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.147 (+/-0.133)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 0.03162277660168379, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.340 (+/-0.290)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 0.03162277660168379, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.292 (+/-0.061)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 0.03162277660168379, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.155 (+/-0.117)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 0.03162277660168379, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.147 (+/-0.133)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 0.03162277660168379, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.378 (+/-0.269)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 0.03162277660168379, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.292 (+/-0.061)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.187 (+/-0.234)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.119 (+/-0.111)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.337 (+/-0.272)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.309 (+/-0.362)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 0.1, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.155 (+/-0.117)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 0.1, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.147 (+/-0.133)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 0.1, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.377 (+/-0.287)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 0.1, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.286 (+/-0.082)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.155 (+/-0.117)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.147 (+/-0.133)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.378 (+/-0.269)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.292 (+/-0.061)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 0.31622776601683794, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.265 (+/-0.332)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 0.31622776601683794, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.235 (+/-0.237)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 0.31622776601683794, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.319 (+/-0.151)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 0.31622776601683794, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.279 (+/-0.140)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 0.31622776601683794, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.155 (+/-0.117)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 0.31622776601683794, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.147 (+/-0.133)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 0.31622776601683794, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.411 (+/-0.130)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 0.31622776601683794, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.292 (+/-0.081)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 0.31622776601683794, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.155 (+/-0.117)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 0.31622776601683794, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.147 (+/-0.133)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 0.31622776601683794, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.378 (+/-0.269)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 0.31622776601683794, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.292 (+/-0.061)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 1.0, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.205 (+/-0.231)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 1.0, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.219 (+/-0.262)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 1.0, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.223 (+/-0.252)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 1.0, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.244 (+/-0.204)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 1.0, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.155 (+/-0.117)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 1.0, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.153 (+/-0.147)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 1.0, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.442 (+/-0.073)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 1.0, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.292 (+/-0.081)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 1.0, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.155 (+/-0.117)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 1.0, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.147 (+/-0.133)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 1.0, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.378 (+/-0.269)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 1.0, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.292 (+/-0.061)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 3.1622776601683795, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 3.1622776601683795, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.136 (+/-0.337)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 3.1622776601683795, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.089 (+/-0.237)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 3.1622776601683795, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.225 (+/-0.116)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 3.1622776601683795, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.148 (+/-0.114)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 3.1622776601683795, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.153 (+/-0.147)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 3.1622776601683795, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.429 (+/-0.168)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 3.1622776601683795, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.292 (+/-0.081)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 3.1622776601683795, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.155 (+/-0.117)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 3.1622776601683795, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.147 (+/-0.133)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 3.1622776601683795, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.378 (+/-0.269)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 3.1622776601683795, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.292 (+/-0.061)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 10.0, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 10.0, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.056 (+/-0.224)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 10.0, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 10.0, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.266 (+/-0.060)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 10.0, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.148 (+/-0.114)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 10.0, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.147 (+/-0.133)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 10.0, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.402 (+/-0.182)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 10.0, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.286 (+/-0.082)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 10.0, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.155 (+/-0.117)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 10.0, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.147 (+/-0.133)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 10.0, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.378 (+/-0.269)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 10.0, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.292 (+/-0.061)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 31.622776601683793, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 31.622776601683793, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.059 (+/-0.236)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 31.622776601683793, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.089 (+/-0.237)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 31.622776601683793, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.192 (+/-0.110)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 31.622776601683793, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.148 (+/-0.114)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 31.622776601683793, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.153 (+/-0.147)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 31.622776601683793, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.400 (+/-0.269)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 31.622776601683793, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.286 (+/-0.082)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 31.622776601683793, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.155 (+/-0.117)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 31.622776601683793, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.147 (+/-0.133)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 31.622776601683793, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.378 (+/-0.269)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 31.622776601683793, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.292 (+/-0.061)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 100.0, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 100.0, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.056 (+/-0.225)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 100.0, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 100.0, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.267 (+/-0.050)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 100.0, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.155 (+/-0.117)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 100.0, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.153 (+/-0.147)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 100.0, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.327 (+/-0.303)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 100.0, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.292 (+/-0.081)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 100.0, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.155 (+/-0.117)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 100.0, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.147 (+/-0.133)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 100.0, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.378 (+/-0.269)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 100.0, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.292 (+/-0.061)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 316.22776601683796, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 316.22776601683796, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.056 (+/-0.224)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 316.22776601683796, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.085 (+/-0.223)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 316.22776601683796, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.255 (+/-0.060)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 316.22776601683796, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.148 (+/-0.114)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 316.22776601683796, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.153 (+/-0.147)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 316.22776601683796, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.368 (+/-0.142)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 316.22776601683796, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.298 (+/-0.057)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 316.22776601683796, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.155 (+/-0.117)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 316.22776601683796, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.147 (+/-0.133)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 316.22776601683796, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.378 (+/-0.269)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 316.22776601683796, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.292 (+/-0.061)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 1000.0, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 1000.0, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.087 (+/-0.230)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 1000.0, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 1000.0, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.260 (+/-0.041)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 1000.0, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.148 (+/-0.114)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 1000.0, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.147 (+/-0.133)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 1000.0, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.485 (+/-0.102)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 1000.0, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.292 (+/-0.081)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 1000.0, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.155 (+/-0.117)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 1000.0, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.147 (+/-0.133)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 1000.0, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.378 (+/-0.269)\n",
      "\n",
      "for {'alpha': 0.31622776601683794, 'eta0': 1000.0, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.292 (+/-0.061)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 1e-05, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.209 (+/-0.093)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 1e-05, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.303 (+/-0.037)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 1e-05, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.482 (+/-0.064)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 1e-05, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.298 (+/-0.057)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 1e-05, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.202 (+/-0.103)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 1e-05, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.303 (+/-0.037)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 1e-05, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.495 (+/-0.061)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 1e-05, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.298 (+/-0.057)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 1e-05, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 1e-05, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.008 (+/-0.032)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 1e-05, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.377 (+/-0.139)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 1e-05, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.215 (+/-0.112)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.114 (+/-0.078)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.113 (+/-0.102)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.474 (+/-0.102)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.269 (+/-0.079)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.106 (+/-0.083)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.113 (+/-0.102)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.386 (+/-0.190)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.263 (+/-0.080)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.008 (+/-0.032)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.377 (+/-0.139)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.215 (+/-0.112)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 0.0001, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.047 (+/-0.058)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 0.0001, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.039 (+/-0.084)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 0.0001, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.442 (+/-0.026)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 0.0001, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.233 (+/-0.099)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 0.0001, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.024 (+/-0.063)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 0.0001, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.039 (+/-0.084)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 0.0001, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.326 (+/-0.251)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 0.0001, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.233 (+/-0.099)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 0.0001, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 0.0001, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.008 (+/-0.032)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 0.0001, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.377 (+/-0.139)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 0.0001, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.215 (+/-0.112)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 0.00031622776601683794, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 0.00031622776601683794, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.008 (+/-0.032)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 0.00031622776601683794, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.428 (+/-0.081)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 0.00031622776601683794, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.215 (+/-0.112)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 0.00031622776601683794, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 0.00031622776601683794, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.008 (+/-0.032)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 0.00031622776601683794, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.391 (+/-0.180)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 0.00031622776601683794, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.215 (+/-0.112)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 0.00031622776601683794, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 0.00031622776601683794, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.008 (+/-0.032)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 0.00031622776601683794, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.377 (+/-0.139)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 0.00031622776601683794, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.215 (+/-0.112)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 0.001, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 0.001, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 0.001, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.421 (+/-0.172)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 0.001, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.215 (+/-0.112)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 0.001, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 0.001, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 0.001, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.382 (+/-0.306)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 0.001, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.215 (+/-0.112)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 0.001, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 0.001, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.008 (+/-0.032)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 0.001, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.377 (+/-0.139)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 0.001, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.215 (+/-0.112)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 0.0031622776601683794, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.008 (+/-0.032)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 0.0031622776601683794, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 0.0031622776601683794, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.374 (+/-0.225)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 0.0031622776601683794, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.210 (+/-0.047)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 0.0031622776601683794, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 0.0031622776601683794, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 0.0031622776601683794, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.480 (+/-0.097)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 0.0031622776601683794, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.215 (+/-0.112)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 0.0031622776601683794, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 0.0031622776601683794, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.008 (+/-0.032)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 0.0031622776601683794, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.377 (+/-0.139)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 0.0031622776601683794, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.215 (+/-0.112)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.047 (+/-0.076)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.016 (+/-0.039)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.394 (+/-0.231)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.179 (+/-0.146)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 0.01, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 0.01, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 0.01, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.423 (+/-0.122)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 0.01, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.215 (+/-0.112)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.008 (+/-0.032)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.377 (+/-0.139)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.215 (+/-0.112)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 0.03162277660168379, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.083 (+/-0.139)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 0.03162277660168379, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.016 (+/-0.039)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 0.03162277660168379, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.332 (+/-0.267)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 0.03162277660168379, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.212 (+/-0.329)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 0.03162277660168379, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 0.03162277660168379, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 0.03162277660168379, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.411 (+/-0.102)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 0.03162277660168379, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.215 (+/-0.112)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 0.03162277660168379, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 0.03162277660168379, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.008 (+/-0.032)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 0.03162277660168379, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.377 (+/-0.139)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 0.03162277660168379, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.215 (+/-0.112)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.152 (+/-0.234)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.039 (+/-0.084)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.281 (+/-0.254)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.346 (+/-0.234)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 0.1, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 0.1, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 0.1, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.346 (+/-0.272)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 0.1, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.215 (+/-0.112)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.008 (+/-0.032)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.377 (+/-0.139)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.215 (+/-0.112)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 0.31622776601683794, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.147 (+/-0.226)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 0.31622776601683794, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.123 (+/-0.349)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 0.31622776601683794, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.241 (+/-0.284)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 0.31622776601683794, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.329 (+/-0.215)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 0.31622776601683794, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 0.31622776601683794, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 0.31622776601683794, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.498 (+/-0.159)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 0.31622776601683794, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.215 (+/-0.112)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 0.31622776601683794, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 0.31622776601683794, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.008 (+/-0.032)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 0.31622776601683794, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.377 (+/-0.139)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 0.31622776601683794, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.215 (+/-0.112)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 1.0, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.068 (+/-0.236)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 1.0, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.056 (+/-0.225)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 1.0, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 1.0, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.206 (+/-0.119)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 1.0, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 1.0, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 1.0, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.500 (+/-0.092)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 1.0, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.215 (+/-0.112)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 1.0, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 1.0, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.008 (+/-0.032)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 1.0, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.377 (+/-0.139)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 1.0, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.215 (+/-0.112)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 3.1622776601683795, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 3.1622776601683795, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.136 (+/-0.337)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 3.1622776601683795, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.089 (+/-0.237)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 3.1622776601683795, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.225 (+/-0.116)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 3.1622776601683795, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 3.1622776601683795, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 3.1622776601683795, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.370 (+/-0.131)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 3.1622776601683795, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.215 (+/-0.112)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 3.1622776601683795, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 3.1622776601683795, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.008 (+/-0.032)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 3.1622776601683795, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.377 (+/-0.139)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 3.1622776601683795, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.215 (+/-0.112)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 10.0, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 10.0, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.056 (+/-0.224)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 10.0, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 10.0, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.266 (+/-0.060)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 10.0, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 10.0, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 10.0, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.480 (+/-0.112)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 10.0, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.215 (+/-0.112)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 10.0, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 10.0, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.008 (+/-0.032)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 10.0, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.377 (+/-0.139)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 10.0, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.215 (+/-0.112)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 31.622776601683793, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 31.622776601683793, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.059 (+/-0.236)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 31.622776601683793, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.089 (+/-0.237)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 31.622776601683793, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.192 (+/-0.110)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 31.622776601683793, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 31.622776601683793, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 31.622776601683793, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.366 (+/-0.096)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 31.622776601683793, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.215 (+/-0.112)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 31.622776601683793, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 31.622776601683793, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.008 (+/-0.032)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 31.622776601683793, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.377 (+/-0.139)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 31.622776601683793, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.215 (+/-0.112)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 100.0, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 100.0, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.056 (+/-0.225)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 100.0, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 100.0, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.267 (+/-0.050)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 100.0, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 100.0, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 100.0, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.398 (+/-0.115)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 100.0, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.215 (+/-0.112)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 100.0, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 100.0, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.008 (+/-0.032)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 100.0, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.377 (+/-0.139)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 100.0, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.215 (+/-0.112)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 316.22776601683796, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 316.22776601683796, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.056 (+/-0.224)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 316.22776601683796, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.085 (+/-0.223)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 316.22776601683796, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.255 (+/-0.060)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 316.22776601683796, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 316.22776601683796, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 316.22776601683796, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.361 (+/-0.153)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 316.22776601683796, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.215 (+/-0.112)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 316.22776601683796, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 316.22776601683796, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.008 (+/-0.032)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 316.22776601683796, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.377 (+/-0.139)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 316.22776601683796, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.215 (+/-0.112)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 1000.0, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 1000.0, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.087 (+/-0.230)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 1000.0, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 1000.0, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.260 (+/-0.041)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 1000.0, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 1000.0, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 1000.0, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.448 (+/-0.150)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 1000.0, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.215 (+/-0.112)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 1000.0, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 1000.0, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.008 (+/-0.032)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 1000.0, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.377 (+/-0.139)\n",
      "\n",
      "for {'alpha': 1.0, 'eta0': 1000.0, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.215 (+/-0.112)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 1e-05, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 1e-05, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.195 (+/-0.112)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 1e-05, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.474 (+/-0.102)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 1e-05, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.155 (+/-0.109)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 1e-05, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 1e-05, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.195 (+/-0.112)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 1e-05, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.435 (+/-0.160)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 1e-05, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.155 (+/-0.109)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 1e-05, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 1e-05, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 1e-05, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.047 (+/-0.075)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 1e-05, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.016 (+/-0.063)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.442 (+/-0.026)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.062 (+/-0.102)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.326 (+/-0.251)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.062 (+/-0.102)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.047 (+/-0.075)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.016 (+/-0.063)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 0.0001, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 0.0001, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 0.0001, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.428 (+/-0.081)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 0.0001, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.047 (+/-0.075)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 0.0001, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 0.0001, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 0.0001, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.350 (+/-0.220)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 0.0001, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.047 (+/-0.075)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 0.0001, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 0.0001, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 0.0001, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.047 (+/-0.075)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 0.0001, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.016 (+/-0.063)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 0.00031622776601683794, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 0.00031622776601683794, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 0.00031622776601683794, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.421 (+/-0.172)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 0.00031622776601683794, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.031 (+/-0.090)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 0.00031622776601683794, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 0.00031622776601683794, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 0.00031622776601683794, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.375 (+/-0.178)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 0.00031622776601683794, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.039 (+/-0.084)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 0.00031622776601683794, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 0.00031622776601683794, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 0.00031622776601683794, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.047 (+/-0.075)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 0.00031622776601683794, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.016 (+/-0.063)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 0.001, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 0.001, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 0.001, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.374 (+/-0.225)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 0.001, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.032 (+/-0.059)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 0.001, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 0.001, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 0.001, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.392 (+/-0.213)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 0.001, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.039 (+/-0.084)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 0.001, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 0.001, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 0.001, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.047 (+/-0.075)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 0.001, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.016 (+/-0.063)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 0.0031622776601683794, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 0.0031622776601683794, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 0.0031622776601683794, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.365 (+/-0.150)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 0.0031622776601683794, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.032 (+/-0.032)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 0.0031622776601683794, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 0.0031622776601683794, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 0.0031622776601683794, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.464 (+/-0.139)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 0.0031622776601683794, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.031 (+/-0.090)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 0.0031622776601683794, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 0.0031622776601683794, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 0.0031622776601683794, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.047 (+/-0.075)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 0.0031622776601683794, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.016 (+/-0.063)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.259 (+/-0.136)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.039 (+/-0.070)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 0.01, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 0.01, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 0.01, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.421 (+/-0.143)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 0.01, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.031 (+/-0.090)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.047 (+/-0.075)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.016 (+/-0.063)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 0.03162277660168379, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.016 (+/-0.063)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 0.03162277660168379, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 0.03162277660168379, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.324 (+/-0.143)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 0.03162277660168379, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.091 (+/-0.128)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 0.03162277660168379, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 0.03162277660168379, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 0.03162277660168379, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.407 (+/-0.128)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 0.03162277660168379, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.023 (+/-0.092)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 0.03162277660168379, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 0.03162277660168379, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 0.03162277660168379, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.047 (+/-0.075)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 0.03162277660168379, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.016 (+/-0.063)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.061 (+/-0.242)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.008 (+/-0.032)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.241 (+/-0.284)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.069 (+/-0.088)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 0.1, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 0.1, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 0.1, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.403 (+/-0.315)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 0.1, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.031 (+/-0.090)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.047 (+/-0.075)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.016 (+/-0.063)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 0.31622776601683794, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.147 (+/-0.168)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 0.31622776601683794, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.079 (+/-0.315)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 0.31622776601683794, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 0.31622776601683794, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.067 (+/-0.168)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 0.31622776601683794, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 0.31622776601683794, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 0.31622776601683794, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.410 (+/-0.077)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 0.31622776601683794, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.031 (+/-0.090)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 0.31622776601683794, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 0.31622776601683794, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 0.31622776601683794, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.047 (+/-0.075)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 0.31622776601683794, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.016 (+/-0.063)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 1.0, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.068 (+/-0.236)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 1.0, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.056 (+/-0.225)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 1.0, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 1.0, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.206 (+/-0.119)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 1.0, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 1.0, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 1.0, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.490 (+/-0.206)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 1.0, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.039 (+/-0.084)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 1.0, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 1.0, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 1.0, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.047 (+/-0.075)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 1.0, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.016 (+/-0.063)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 3.1622776601683795, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 3.1622776601683795, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.136 (+/-0.337)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 3.1622776601683795, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.089 (+/-0.237)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 3.1622776601683795, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.225 (+/-0.116)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 3.1622776601683795, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 3.1622776601683795, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 3.1622776601683795, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.433 (+/-0.172)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 3.1622776601683795, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.039 (+/-0.084)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 3.1622776601683795, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 3.1622776601683795, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 3.1622776601683795, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.047 (+/-0.075)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 3.1622776601683795, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.016 (+/-0.063)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 10.0, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 10.0, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.056 (+/-0.224)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 10.0, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 10.0, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.266 (+/-0.060)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 10.0, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 10.0, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 10.0, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.467 (+/-0.076)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 10.0, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.039 (+/-0.084)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 10.0, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 10.0, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 10.0, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.047 (+/-0.075)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 10.0, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.016 (+/-0.063)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 31.622776601683793, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 31.622776601683793, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.059 (+/-0.236)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 31.622776601683793, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.089 (+/-0.237)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 31.622776601683793, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.192 (+/-0.110)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 31.622776601683793, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 31.622776601683793, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 31.622776601683793, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.364 (+/-0.233)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 31.622776601683793, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.039 (+/-0.084)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 31.622776601683793, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 31.622776601683793, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 31.622776601683793, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.047 (+/-0.075)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 31.622776601683793, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.016 (+/-0.063)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 100.0, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 100.0, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.056 (+/-0.225)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 100.0, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 100.0, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.267 (+/-0.050)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 100.0, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 100.0, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 100.0, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.409 (+/-0.232)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 100.0, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.031 (+/-0.090)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 100.0, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 100.0, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 100.0, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.047 (+/-0.075)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 100.0, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.016 (+/-0.063)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 316.22776601683796, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 316.22776601683796, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.056 (+/-0.224)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 316.22776601683796, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.085 (+/-0.223)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 316.22776601683796, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.255 (+/-0.060)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 316.22776601683796, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 316.22776601683796, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 316.22776601683796, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.423 (+/-0.132)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 316.22776601683796, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.023 (+/-0.092)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 316.22776601683796, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 316.22776601683796, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 316.22776601683796, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.047 (+/-0.075)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 316.22776601683796, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.016 (+/-0.063)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 1000.0, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 1000.0, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.087 (+/-0.230)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 1000.0, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 1000.0, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.260 (+/-0.041)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 1000.0, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 1000.0, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 1000.0, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.414 (+/-0.129)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 1000.0, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.031 (+/-0.090)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 1000.0, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 1000.0, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 1000.0, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.047 (+/-0.075)\n",
      "\n",
      "for {'alpha': 3.1622776601683795, 'eta0': 1000.0, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.016 (+/-0.063)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 1e-05, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 1e-05, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 1e-05, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.442 (+/-0.026)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 1e-05, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 1e-05, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 1e-05, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 1e-05, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.458 (+/-0.061)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 1e-05, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 1e-05, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 1e-05, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 1e-05, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 1e-05, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.428 (+/-0.081)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.350 (+/-0.220)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 0.0001, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 0.0001, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 0.0001, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.421 (+/-0.172)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 0.0001, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 0.0001, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 0.0001, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 0.0001, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.414 (+/-0.257)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 0.0001, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 0.0001, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 0.0001, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 0.0001, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 0.0001, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 0.00031622776601683794, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 0.00031622776601683794, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 0.00031622776601683794, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.374 (+/-0.225)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 0.00031622776601683794, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 0.00031622776601683794, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 0.00031622776601683794, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 0.00031622776601683794, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.370 (+/-0.190)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 0.00031622776601683794, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 0.00031622776601683794, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 0.00031622776601683794, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 0.00031622776601683794, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 0.00031622776601683794, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 0.001, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 0.001, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 0.001, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.365 (+/-0.150)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 0.001, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 0.001, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 0.001, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 0.001, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.404 (+/-0.124)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 0.001, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 0.001, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 0.001, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 0.001, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 0.001, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 0.0031622776601683794, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 0.0031622776601683794, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 0.0031622776601683794, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.259 (+/-0.137)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 0.0031622776601683794, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 0.0031622776601683794, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 0.0031622776601683794, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 0.0031622776601683794, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.503 (+/-0.137)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 0.0031622776601683794, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 0.0031622776601683794, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 0.0031622776601683794, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 0.0031622776601683794, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 0.0031622776601683794, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.269 (+/-0.153)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 0.01, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 0.01, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 0.01, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.421 (+/-0.206)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 0.01, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 0.03162277660168379, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 0.03162277660168379, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 0.03162277660168379, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.170 (+/-0.272)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 0.03162277660168379, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.022 (+/-0.089)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 0.03162277660168379, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 0.03162277660168379, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 0.03162277660168379, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.491 (+/-0.061)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 0.03162277660168379, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 0.03162277660168379, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 0.03162277660168379, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 0.03162277660168379, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 0.03162277660168379, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.166 (+/-0.300)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 0.1, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 0.1, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 0.1, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.442 (+/-0.169)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 0.1, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 0.31622776601683794, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.147 (+/-0.168)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 0.31622776601683794, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.079 (+/-0.315)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 0.31622776601683794, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 0.31622776601683794, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.067 (+/-0.168)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 0.31622776601683794, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 0.31622776601683794, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 0.31622776601683794, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.454 (+/-0.107)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 0.31622776601683794, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 0.31622776601683794, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 0.31622776601683794, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 0.31622776601683794, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 0.31622776601683794, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 1.0, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.068 (+/-0.236)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 1.0, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.056 (+/-0.225)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 1.0, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 1.0, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.206 (+/-0.119)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 1.0, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 1.0, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 1.0, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.450 (+/-0.080)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 1.0, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 1.0, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 1.0, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 1.0, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 1.0, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 3.1622776601683795, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 3.1622776601683795, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.136 (+/-0.337)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 3.1622776601683795, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.089 (+/-0.237)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 3.1622776601683795, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.225 (+/-0.116)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 3.1622776601683795, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 3.1622776601683795, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 3.1622776601683795, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.396 (+/-0.165)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 3.1622776601683795, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 3.1622776601683795, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 3.1622776601683795, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 3.1622776601683795, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 3.1622776601683795, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 10.0, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 10.0, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.056 (+/-0.224)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 10.0, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 10.0, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.266 (+/-0.060)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 10.0, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 10.0, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 10.0, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.456 (+/-0.109)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 10.0, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 10.0, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 10.0, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 10.0, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 10.0, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 31.622776601683793, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 31.622776601683793, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.059 (+/-0.236)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 31.622776601683793, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.089 (+/-0.237)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 31.622776601683793, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.192 (+/-0.110)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 31.622776601683793, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 31.622776601683793, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 31.622776601683793, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.399 (+/-0.157)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 31.622776601683793, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 31.622776601683793, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 31.622776601683793, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 31.622776601683793, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 31.622776601683793, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 100.0, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 100.0, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.056 (+/-0.225)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 100.0, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 100.0, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.267 (+/-0.050)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 100.0, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 100.0, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 100.0, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.351 (+/-0.319)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 100.0, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 100.0, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 100.0, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 100.0, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 100.0, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 316.22776601683796, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 316.22776601683796, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.056 (+/-0.224)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 316.22776601683796, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.085 (+/-0.223)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 316.22776601683796, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.255 (+/-0.060)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 316.22776601683796, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 316.22776601683796, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 316.22776601683796, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.392 (+/-0.157)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 316.22776601683796, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 316.22776601683796, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 316.22776601683796, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 316.22776601683796, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 316.22776601683796, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 1000.0, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 1000.0, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.087 (+/-0.230)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 1000.0, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 1000.0, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.260 (+/-0.041)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 1000.0, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 1000.0, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 1000.0, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.361 (+/-0.209)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 1000.0, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 1000.0, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 1000.0, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 1000.0, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 10.0, 'eta0': 1000.0, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 1e-05, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 1e-05, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 1e-05, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.428 (+/-0.081)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 1e-05, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 1e-05, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 1e-05, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 1e-05, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.459 (+/-0.079)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 1e-05, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 1e-05, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 1e-05, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 1e-05, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 1e-05, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.421 (+/-0.172)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.414 (+/-0.257)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 0.0001, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 0.0001, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 0.0001, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.374 (+/-0.225)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 0.0001, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 0.0001, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 0.0001, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 0.0001, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.302 (+/-0.286)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 0.0001, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 0.0001, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 0.0001, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 0.0001, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 0.0001, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 0.00031622776601683794, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 0.00031622776601683794, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 0.00031622776601683794, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.365 (+/-0.150)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 0.00031622776601683794, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 0.00031622776601683794, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 0.00031622776601683794, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 0.00031622776601683794, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.390 (+/-0.138)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 0.00031622776601683794, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 0.00031622776601683794, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 0.00031622776601683794, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 0.00031622776601683794, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 0.00031622776601683794, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 0.001, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 0.001, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 0.001, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.259 (+/-0.137)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 0.001, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 0.001, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 0.001, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 0.001, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.373 (+/-0.146)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 0.001, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 0.001, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 0.001, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 0.001, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 0.001, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 0.0031622776601683794, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 0.0031622776601683794, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 0.0031622776601683794, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.218 (+/-0.245)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 0.0031622776601683794, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 0.0031622776601683794, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 0.0031622776601683794, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 0.0031622776601683794, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.475 (+/-0.078)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 0.0031622776601683794, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 0.0031622776601683794, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 0.0031622776601683794, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 0.0031622776601683794, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 0.0031622776601683794, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.094 (+/-0.246)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 0.01, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 0.01, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 0.01, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.401 (+/-0.192)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 0.01, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 0.03162277660168379, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 0.03162277660168379, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 0.03162277660168379, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.059 (+/-0.237)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 0.03162277660168379, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 0.03162277660168379, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 0.03162277660168379, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 0.03162277660168379, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.480 (+/-0.141)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 0.03162277660168379, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 0.03162277660168379, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 0.03162277660168379, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 0.03162277660168379, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 0.03162277660168379, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.166 (+/-0.300)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 0.1, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 0.1, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 0.1, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.458 (+/-0.074)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 0.1, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 0.31622776601683794, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.147 (+/-0.168)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 0.31622776601683794, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.079 (+/-0.315)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 0.31622776601683794, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 0.31622776601683794, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.067 (+/-0.168)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 0.31622776601683794, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 0.31622776601683794, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 0.31622776601683794, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.484 (+/-0.129)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 0.31622776601683794, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 0.31622776601683794, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 0.31622776601683794, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 0.31622776601683794, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 0.31622776601683794, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 1.0, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.068 (+/-0.236)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 1.0, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.056 (+/-0.225)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 1.0, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 1.0, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.206 (+/-0.119)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 1.0, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 1.0, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 1.0, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.445 (+/-0.127)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 1.0, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 1.0, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 1.0, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 1.0, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 1.0, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 3.1622776601683795, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 3.1622776601683795, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.136 (+/-0.337)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 3.1622776601683795, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.089 (+/-0.237)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 3.1622776601683795, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.225 (+/-0.116)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 3.1622776601683795, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 3.1622776601683795, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 3.1622776601683795, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.446 (+/-0.081)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 3.1622776601683795, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 3.1622776601683795, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 3.1622776601683795, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 3.1622776601683795, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 3.1622776601683795, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 10.0, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 10.0, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.056 (+/-0.224)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 10.0, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 10.0, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.266 (+/-0.060)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 10.0, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 10.0, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 10.0, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.407 (+/-0.146)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 10.0, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 10.0, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 10.0, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 10.0, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 10.0, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 31.622776601683793, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 31.622776601683793, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.059 (+/-0.236)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 31.622776601683793, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.089 (+/-0.237)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 31.622776601683793, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.192 (+/-0.110)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 31.622776601683793, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 31.622776601683793, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 31.622776601683793, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.461 (+/-0.090)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 31.622776601683793, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 31.622776601683793, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 31.622776601683793, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 31.622776601683793, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 31.622776601683793, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 100.0, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 100.0, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.056 (+/-0.225)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 100.0, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 100.0, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.267 (+/-0.050)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 100.0, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 100.0, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 100.0, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.301 (+/-0.212)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 100.0, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 100.0, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 100.0, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 100.0, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 100.0, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 316.22776601683796, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 316.22776601683796, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.056 (+/-0.224)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 316.22776601683796, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.085 (+/-0.223)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 316.22776601683796, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.255 (+/-0.060)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 316.22776601683796, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 316.22776601683796, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 316.22776601683796, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.407 (+/-0.136)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 316.22776601683796, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 316.22776601683796, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 316.22776601683796, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 316.22776601683796, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 316.22776601683796, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 1000.0, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 1000.0, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.087 (+/-0.230)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 1000.0, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 1000.0, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.260 (+/-0.041)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 1000.0, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 1000.0, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 1000.0, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.425 (+/-0.179)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 1000.0, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 1000.0, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 1000.0, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 1000.0, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 31.622776601683793, 'eta0': 1000.0, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 1e-05, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 1e-05, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 1e-05, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.421 (+/-0.172)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 1e-05, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 1e-05, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 1e-05, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 1e-05, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.470 (+/-0.119)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 1e-05, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 1e-05, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 1e-05, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 1e-05, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 1e-05, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.374 (+/-0.225)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.302 (+/-0.286)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 0.0001, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 0.0001, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 0.0001, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.365 (+/-0.150)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 0.0001, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 0.0001, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 0.0001, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 0.0001, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.376 (+/-0.267)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 0.0001, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 0.0001, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 0.0001, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 0.0001, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 0.0001, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 0.00031622776601683794, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 0.00031622776601683794, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 0.00031622776601683794, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.259 (+/-0.137)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 0.00031622776601683794, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 0.00031622776601683794, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 0.00031622776601683794, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 0.00031622776601683794, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.405 (+/-0.272)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 0.00031622776601683794, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 0.00031622776601683794, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 0.00031622776601683794, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 0.00031622776601683794, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 0.00031622776601683794, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 0.001, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 0.001, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 0.001, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.218 (+/-0.245)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 0.001, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 0.001, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 0.001, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 0.001, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.406 (+/-0.227)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 0.001, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 0.001, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 0.001, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 0.001, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 0.001, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 0.0031622776601683794, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 0.0031622776601683794, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 0.0031622776601683794, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.060 (+/-0.242)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 0.0031622776601683794, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 0.0031622776601683794, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 0.0031622776601683794, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 0.0031622776601683794, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.501 (+/-0.162)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 0.0031622776601683794, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 0.0031622776601683794, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 0.0031622776601683794, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 0.0031622776601683794, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 0.0031622776601683794, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.059 (+/-0.237)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 0.01, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 0.01, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 0.01, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.514 (+/-0.078)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 0.01, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 0.03162277660168379, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 0.03162277660168379, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 0.03162277660168379, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 0.03162277660168379, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 0.03162277660168379, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 0.03162277660168379, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 0.03162277660168379, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.478 (+/-0.151)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 0.03162277660168379, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 0.03162277660168379, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 0.03162277660168379, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 0.03162277660168379, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 0.03162277660168379, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.166 (+/-0.300)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 0.1, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 0.1, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 0.1, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.441 (+/-0.093)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 0.1, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 0.31622776601683794, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.147 (+/-0.168)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 0.31622776601683794, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.079 (+/-0.315)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 0.31622776601683794, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 0.31622776601683794, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.067 (+/-0.168)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 0.31622776601683794, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 0.31622776601683794, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 0.31622776601683794, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.429 (+/-0.162)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 0.31622776601683794, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 0.31622776601683794, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 0.31622776601683794, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 0.31622776601683794, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 0.31622776601683794, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 1.0, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.068 (+/-0.236)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 1.0, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.056 (+/-0.225)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 1.0, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 1.0, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.206 (+/-0.119)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 1.0, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 1.0, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 1.0, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.425 (+/-0.114)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 1.0, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 1.0, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 1.0, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 1.0, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 1.0, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 3.1622776601683795, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 3.1622776601683795, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.136 (+/-0.337)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 3.1622776601683795, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.089 (+/-0.237)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 3.1622776601683795, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.225 (+/-0.116)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 3.1622776601683795, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 3.1622776601683795, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 3.1622776601683795, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.413 (+/-0.088)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 3.1622776601683795, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 3.1622776601683795, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 3.1622776601683795, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 3.1622776601683795, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 3.1622776601683795, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 10.0, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 10.0, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.056 (+/-0.224)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 10.0, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 10.0, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.266 (+/-0.060)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 10.0, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 10.0, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 10.0, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.461 (+/-0.207)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 10.0, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 10.0, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 10.0, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 10.0, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 10.0, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 31.622776601683793, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 31.622776601683793, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.059 (+/-0.236)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 31.622776601683793, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.089 (+/-0.237)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 31.622776601683793, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.192 (+/-0.110)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 31.622776601683793, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 31.622776601683793, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 31.622776601683793, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.468 (+/-0.119)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 31.622776601683793, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 31.622776601683793, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 31.622776601683793, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 31.622776601683793, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 31.622776601683793, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 100.0, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 100.0, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.056 (+/-0.225)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 100.0, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 100.0, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.267 (+/-0.050)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 100.0, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 100.0, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 100.0, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.347 (+/-0.303)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 100.0, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 100.0, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 100.0, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 100.0, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 100.0, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 316.22776601683796, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 316.22776601683796, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.056 (+/-0.224)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 316.22776601683796, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.085 (+/-0.223)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 316.22776601683796, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.255 (+/-0.060)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 316.22776601683796, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 316.22776601683796, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 316.22776601683796, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.420 (+/-0.156)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 316.22776601683796, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 316.22776601683796, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 316.22776601683796, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 316.22776601683796, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 316.22776601683796, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 1000.0, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 1000.0, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.087 (+/-0.230)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 1000.0, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 1000.0, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.260 (+/-0.041)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 1000.0, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 1000.0, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 1000.0, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.396 (+/-0.171)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 1000.0, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 1000.0, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 1000.0, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 1000.0, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 100.0, 'eta0': 1000.0, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 1e-05, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 1e-05, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 1e-05, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.374 (+/-0.225)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 1e-05, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 1e-05, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 1e-05, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 1e-05, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.418 (+/-0.084)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 1e-05, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 1e-05, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 1e-05, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 1e-05, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 1e-05, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.365 (+/-0.150)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.376 (+/-0.267)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 0.0001, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 0.0001, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 0.0001, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.259 (+/-0.137)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 0.0001, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 0.0001, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 0.0001, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 0.0001, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.364 (+/-0.293)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 0.0001, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 0.0001, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 0.0001, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 0.0001, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 0.0001, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 0.00031622776601683794, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 0.00031622776601683794, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 0.00031622776601683794, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.218 (+/-0.245)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 0.00031622776601683794, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 0.00031622776601683794, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 0.00031622776601683794, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 0.00031622776601683794, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.397 (+/-0.177)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 0.00031622776601683794, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 0.00031622776601683794, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 0.00031622776601683794, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 0.00031622776601683794, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 0.00031622776601683794, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 0.001, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 0.001, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 0.001, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.060 (+/-0.242)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 0.001, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 0.001, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 0.001, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 0.001, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.398 (+/-0.125)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 0.001, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 0.001, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 0.001, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 0.001, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 0.001, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 0.0031622776601683794, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 0.0031622776601683794, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 0.0031622776601683794, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.059 (+/-0.237)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 0.0031622776601683794, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 0.0031622776601683794, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 0.0031622776601683794, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 0.0031622776601683794, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.455 (+/-0.128)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 0.0031622776601683794, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 0.0031622776601683794, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 0.0031622776601683794, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 0.0031622776601683794, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 0.0031622776601683794, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.059 (+/-0.237)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 0.01, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 0.01, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 0.01, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.450 (+/-0.082)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 0.01, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 0.03162277660168379, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 0.03162277660168379, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 0.03162277660168379, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 0.03162277660168379, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 0.03162277660168379, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 0.03162277660168379, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 0.03162277660168379, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.439 (+/-0.152)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 0.03162277660168379, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 0.03162277660168379, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 0.03162277660168379, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 0.03162277660168379, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 0.03162277660168379, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.166 (+/-0.300)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 0.1, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 0.1, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 0.1, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.458 (+/-0.177)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 0.1, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 0.31622776601683794, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.147 (+/-0.168)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 0.31622776601683794, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.079 (+/-0.315)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 0.31622776601683794, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 0.31622776601683794, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.067 (+/-0.168)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 0.31622776601683794, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 0.31622776601683794, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 0.31622776601683794, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.419 (+/-0.124)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 0.31622776601683794, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 0.31622776601683794, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 0.31622776601683794, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 0.31622776601683794, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 0.31622776601683794, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 1.0, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.068 (+/-0.236)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 1.0, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.056 (+/-0.225)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 1.0, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 1.0, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.206 (+/-0.119)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 1.0, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 1.0, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 1.0, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.445 (+/-0.104)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 1.0, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 1.0, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 1.0, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 1.0, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 1.0, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 3.1622776601683795, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 3.1622776601683795, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.136 (+/-0.337)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 3.1622776601683795, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.089 (+/-0.237)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 3.1622776601683795, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.225 (+/-0.116)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 3.1622776601683795, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 3.1622776601683795, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 3.1622776601683795, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.447 (+/-0.103)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 3.1622776601683795, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 3.1622776601683795, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 3.1622776601683795, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 3.1622776601683795, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 3.1622776601683795, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 10.0, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 10.0, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.056 (+/-0.224)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 10.0, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 10.0, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.266 (+/-0.060)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 10.0, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 10.0, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 10.0, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.452 (+/-0.168)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 10.0, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 10.0, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 10.0, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 10.0, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 10.0, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 31.622776601683793, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 31.622776601683793, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.059 (+/-0.236)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 31.622776601683793, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.089 (+/-0.237)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 31.622776601683793, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.192 (+/-0.110)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 31.622776601683793, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 31.622776601683793, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 31.622776601683793, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.424 (+/-0.200)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 31.622776601683793, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 31.622776601683793, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 31.622776601683793, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 31.622776601683793, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 31.622776601683793, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 100.0, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 100.0, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.056 (+/-0.225)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 100.0, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 100.0, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.267 (+/-0.050)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 100.0, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 100.0, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 100.0, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.367 (+/-0.321)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 100.0, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 100.0, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 100.0, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 100.0, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 100.0, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 316.22776601683796, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 316.22776601683796, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.056 (+/-0.224)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 316.22776601683796, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.085 (+/-0.223)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 316.22776601683796, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.255 (+/-0.060)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 316.22776601683796, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 316.22776601683796, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 316.22776601683796, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.421 (+/-0.158)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 316.22776601683796, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 316.22776601683796, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 316.22776601683796, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 316.22776601683796, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 316.22776601683796, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 1000.0, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 1000.0, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.087 (+/-0.230)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 1000.0, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 1000.0, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.260 (+/-0.041)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 1000.0, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 1000.0, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 1000.0, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.387 (+/-0.187)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 1000.0, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 1000.0, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 1000.0, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 1000.0, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 316.22776601683796, 'eta0': 1000.0, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 1e-05, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 1e-05, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 1e-05, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.365 (+/-0.150)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 1e-05, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 1e-05, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 1e-05, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 1e-05, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.475 (+/-0.057)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 1e-05, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 1e-05, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 1e-05, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 1e-05, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 1e-05, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.259 (+/-0.137)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.364 (+/-0.293)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 3.1622776601683795e-05, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 0.0001, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 0.0001, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 0.0001, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.218 (+/-0.245)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 0.0001, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 0.0001, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 0.0001, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 0.0001, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.334 (+/-0.246)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 0.0001, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 0.0001, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 0.0001, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 0.0001, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 0.0001, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 0.00031622776601683794, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 0.00031622776601683794, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 0.00031622776601683794, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.060 (+/-0.242)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 0.00031622776601683794, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 0.00031622776601683794, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 0.00031622776601683794, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 0.00031622776601683794, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.378 (+/-0.085)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 0.00031622776601683794, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 0.00031622776601683794, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 0.00031622776601683794, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 0.00031622776601683794, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 0.00031622776601683794, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 0.001, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 0.001, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 0.001, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.059 (+/-0.237)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 0.001, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 0.001, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 0.001, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 0.001, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.432 (+/-0.121)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 0.001, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 0.001, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 0.001, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 0.001, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 0.001, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 0.0031622776601683794, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 0.0031622776601683794, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 0.0031622776601683794, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.059 (+/-0.237)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 0.0031622776601683794, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 0.0031622776601683794, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 0.0031622776601683794, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 0.0031622776601683794, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.454 (+/-0.124)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 0.0031622776601683794, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 0.0031622776601683794, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 0.0031622776601683794, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 0.0031622776601683794, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 0.0031622776601683794, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.059 (+/-0.237)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 0.01, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 0.01, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 0.01, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.466 (+/-0.097)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 0.01, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 0.03162277660168379, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 0.03162277660168379, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 0.03162277660168379, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 0.03162277660168379, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 0.03162277660168379, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 0.03162277660168379, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 0.03162277660168379, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.462 (+/-0.147)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 0.03162277660168379, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 0.03162277660168379, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 0.03162277660168379, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 0.03162277660168379, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 0.03162277660168379, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.166 (+/-0.300)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 0.1, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 0.1, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 0.1, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.447 (+/-0.126)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 0.1, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 0.31622776601683794, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.147 (+/-0.168)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 0.31622776601683794, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.079 (+/-0.315)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 0.31622776601683794, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 0.31622776601683794, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.067 (+/-0.168)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 0.31622776601683794, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 0.31622776601683794, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 0.31622776601683794, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.394 (+/-0.087)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 0.31622776601683794, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 0.31622776601683794, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 0.31622776601683794, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 0.31622776601683794, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 0.31622776601683794, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 1.0, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.068 (+/-0.236)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 1.0, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.056 (+/-0.225)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 1.0, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 1.0, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.206 (+/-0.119)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 1.0, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 1.0, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 1.0, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.410 (+/-0.133)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 1.0, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 1.0, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 1.0, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 1.0, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 1.0, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 3.1622776601683795, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 3.1622776601683795, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.136 (+/-0.337)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 3.1622776601683795, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.089 (+/-0.237)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 3.1622776601683795, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.225 (+/-0.116)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 3.1622776601683795, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 3.1622776601683795, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 3.1622776601683795, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.399 (+/-0.188)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 3.1622776601683795, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 3.1622776601683795, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 3.1622776601683795, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 3.1622776601683795, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 3.1622776601683795, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 10.0, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 10.0, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.056 (+/-0.224)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 10.0, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 10.0, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.266 (+/-0.060)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 10.0, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 10.0, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 10.0, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.424 (+/-0.220)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 10.0, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 10.0, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 10.0, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 10.0, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 10.0, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 31.622776601683793, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 31.622776601683793, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.059 (+/-0.236)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 31.622776601683793, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.089 (+/-0.237)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 31.622776601683793, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.192 (+/-0.110)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 31.622776601683793, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 31.622776601683793, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 31.622776601683793, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.412 (+/-0.185)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 31.622776601683793, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 31.622776601683793, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 31.622776601683793, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 31.622776601683793, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 31.622776601683793, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 100.0, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 100.0, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.056 (+/-0.225)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 100.0, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 100.0, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.267 (+/-0.050)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 100.0, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 100.0, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 100.0, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.369 (+/-0.359)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 100.0, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 100.0, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 100.0, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 100.0, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 100.0, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 316.22776601683796, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 316.22776601683796, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.056 (+/-0.224)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 316.22776601683796, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.085 (+/-0.223)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 316.22776601683796, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.255 (+/-0.060)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 316.22776601683796, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 316.22776601683796, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 316.22776601683796, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.393 (+/-0.167)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 316.22776601683796, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 316.22776601683796, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 316.22776601683796, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 316.22776601683796, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 316.22776601683796, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 1000.0, 'learning_rate': 'constant', 'loss': 'hinge'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 1000.0, 'learning_rate': 'constant', 'loss': 'log_loss'}\n",
      "0.087 (+/-0.230)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 1000.0, 'learning_rate': 'constant', 'loss': 'perceptron'}\n",
      "0.125 (+/-0.308)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 1000.0, 'learning_rate': 'constant', 'loss': 'squared_error'}\n",
      "0.260 (+/-0.041)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 1000.0, 'learning_rate': 'adaptive', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 1000.0, 'learning_rate': 'adaptive', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 1000.0, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n",
      "0.381 (+/-0.171)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 1000.0, 'learning_rate': 'adaptive', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 1000.0, 'learning_rate': 'optimal', 'loss': 'hinge'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 1000.0, 'learning_rate': 'optimal', 'loss': 'log_loss'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 1000.0, 'learning_rate': 'optimal', 'loss': 'perceptron'}\n",
      "0.000 (+/-0.000)\n",
      "\n",
      "for {'alpha': 1000.0, 'eta0': 1000.0, 'learning_rate': 'optimal', 'loss': 'squared_error'}\n",
      "0.000 (+/-0.000)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = grid.cv_results_\n",
    "for mean_score, std_dev, params in zip(results[\"mean_test_score\"], results[\"std_test_score\"], results[\"params\"]):\n",
    "    print(f\"for {params}\\n{mean_score:.3f} (+/-{std_dev*2:.03f})\\n\")\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 100.0, 'eta0': 0.01, 'learning_rate': 'adaptive', 'loss': 'perceptron'}\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)\n",
    "# for {'alpha': 0.001, 'eta0': 0.001, 'learning_rate': 'constant', 'loss': 'log_loss'} \n",
    "# 0.832 (+/-0.013)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "best=grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "model = SGDClassifier(random_state=42,**best)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "classes = model.classes_\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (accuracy_score,\n",
    "                             classification_report,\n",
    "                             ConfusionMatrixDisplay,\n",
    "                             accuracy_score,\n",
    "                             f1_score,\n",
    "                             recall_score,\n",
    "                             precision_score\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7466307277628033\n",
      "F1 Score: 0.29850746268656714\n",
      "Recall: 0.3225806451612903\n",
      "Precision: 0.2777777777777778\n",
      "Accuracy: 0.7466307277628033\n"
     ]
    }
   ],
   "source": [
    "# Calcular métricas de evaluación\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "\n",
    "# Parametros por defecto\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Precision:\", precision)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.28      0.32      0.30        62\n",
      "           0       0.86      0.83      0.85       309\n",
      "\n",
      "    accuracy                           0.75       371\n",
      "   macro avg       0.57      0.58      0.57       371\n",
      "weighted avg       0.76      0.75      0.75       371\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classes =[1, 0] \n",
    "\n",
    "display=ConfusionMatrixDisplay.from_predictions(\n",
    "    y_test, y_pred, labels=classes, cmap=plt.cm.BuGn)\n",
    "print(classification_report(y_test, y_pred, labels=classes))\n",
    "\n",
    "plt.title('Matriz de Confusión')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 3: Árboles de Decisión\n",
    "\n",
    "En este ejercicio se entrenarán árboles de decisión para predecir la variable objetivo.\n",
    "\n",
    "Para ello, deberán utilizar la clase DecisionTreeClassifier de scikit-learn.\n",
    "\n",
    "Documentación:\n",
    "- https://scikit-learn.org/stable/modules/tree.html\n",
    "  - https://scikit-learn.org/stable/modules/tree.html#tips-on-practical-use\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "- https://scikit-learn.org/stable/auto_examples/tree/plot_unveil_tree_structure.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 3.1: DecisionTreeClassifier con hiperparámetros por defecto\n",
    "\n",
    "Entrenar y evaluar el clasificador DecisionTreeClassifier usando los valores por omisión de scikit-learn para todos los parámetros. Únicamente **fijar la semilla aleatoria** para hacer repetible el experimento.\n",
    "\n",
    "Evaluar sobre el conjunto de **entrenamiento** y sobre el conjunto de **evaluación**, reportando:\n",
    "- Accuracy\n",
    "- Precision\n",
    "- Recall\n",
    "- F1\n",
    "- matriz de confusión\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "\n",
    "model_tree= tree.DecisionTreeClassifier(random_state=42)\n",
    "model_tree.fit(X_train,y_train)\n",
    "y_pred=model_tree.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8840970350404312\n",
      "F1 Score: 0.6194690265486725\n",
      "Recall: 0.5645161290322581\n",
      "Precision: 0.6862745098039216\n"
     ]
    }
   ],
   "source": [
    "# Calcular métricas de evaluación\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Precision:\", precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.56      0.62        62\n",
      "           0       0.92      0.95      0.93       309\n",
      "\n",
      "    accuracy                           0.88       371\n",
      "   macro avg       0.80      0.76      0.78       371\n",
      "weighted avg       0.88      0.88      0.88       371\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classes =[1, 0] \n",
    "\n",
    "display=ConfusionMatrixDisplay.from_predictions(\n",
    "    y_test, y_pred, labels=classes, cmap=plt.cm.BuGn, xticks_rotation='vertical')\n",
    "print(classification_report(y_test, y_pred, labels=classes))\n",
    "\n",
    "plt.title('Matriz de Confusión')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 3.2: Ajuste de Hiperparámetros\n",
    "\n",
    "Seleccionar valores para los hiperparámetros principales del DecisionTreeClassifier. Como mínimo, probar diferentes criterios de partición (criterion), profundidad máxima del árbol (max_depth), y cantidad mínima de samples por hoja (min_samples_leaf).\n",
    "\n",
    "Para ello, usar grid-search y 5-fold cross-validation sobre el conjunto de entrenamiento para explorar muchas combinaciones posibles de valores.\n",
    "\n",
    "Reportar accuracy promedio y varianza para todas las configuraciones.\n",
    "\n",
    "Para la mejor configuración encontrada, evaluar sobre el conjunto de **entrenamiento** y sobre el conjunto de **evaluación**, reportando:\n",
    "- Accuracy\n",
    "- Precision\n",
    "- Recall\n",
    "- F1\n",
    "- matriz de confusión\n",
    "\n",
    "\n",
    "Documentación:\n",
    "- https://scikit-learn.org/stable/modules/grid_search.html\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrica utilizada F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 28800 candidates, totalling 144000 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=DecisionTreeClassifier(random_state=42), n_jobs=-1,\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;],\n",
       "                         &#x27;max_depth&#x27;: array([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "       19]),\n",
       "                         &#x27;min_samples_leaf&#x27;: array([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "       19, 20, 21]),\n",
       "                         &#x27;min_samples_split&#x27;: array([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "       19, 20, 21]),\n",
       "                         &#x27;splitter&#x27;: [&#x27;best&#x27;, &#x27;random&#x27;]},\n",
       "             scoring=&#x27;f1&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=DecisionTreeClassifier(random_state=42), n_jobs=-1,\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;],\n",
       "                         &#x27;max_depth&#x27;: array([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "       19]),\n",
       "                         &#x27;min_samples_leaf&#x27;: array([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "       19, 20, 21]),\n",
       "                         &#x27;min_samples_split&#x27;: array([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "       19, 20, 21]),\n",
       "                         &#x27;splitter&#x27;: [&#x27;best&#x27;, &#x27;random&#x27;]},\n",
       "             scoring=&#x27;f1&#x27;, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=DecisionTreeClassifier(random_state=42), n_jobs=-1,\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': array([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "       19]),\n",
       "                         'min_samples_leaf': array([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "       19, 20, 21]),\n",
       "                         'min_samples_split': array([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "       19, 20, 21]),\n",
       "                         'splitter': ['best', 'random']},\n",
       "             scoring='f1', verbose=1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tree.DecisionTreeClassifier(random_state=42)\n",
    "space = {\n",
    "    'criterion': ['gini','entropy'],\n",
    "    \"splitter\":[\"best\", \"random\"],\n",
    "    'max_depth': np.arange(2,20,1),\n",
    "    'min_samples_split':np.arange(2,22,1),\n",
    "    'min_samples_leaf':np.arange(2,22,1)\n",
    "}\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid = GridSearchCV(model, space, cv=5, verbose=1, n_jobs=-1,scoring='f1')\n",
    "grid.fit(X_train, y_train) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy',\n",
       " 'max_depth': 17,\n",
       " 'min_samples_leaf': 2,\n",
       " 'min_samples_split': 6,\n",
       " 'splitter': 'random'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = grid.cv_results_\n",
    "for mean_score, std_dev, params in zip(results[\"mean_test_score\"], results[\"std_test_score\"], results[\"params\"]):\n",
    "    print(f\"for {params}\\n{mean_score:.3f} (+/-{std_dev*2:.03f})\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "treeCV=tree.DecisionTreeClassifier(random_state=42,**grid.best_params_)\n",
    "treeCV.fit(X_train,y_train)\n",
    "y_pred=treeCV.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8787061994609164\n",
      "F1 Score: 0.6086956521739131\n",
      "Recall: 0.5645161290322581\n",
      "Precision: 0.660377358490566\n"
     ]
    }
   ],
   "source": [
    "# Calcular métricas de evaluación\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Precision:\", precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.66      0.56      0.61        62\n",
      "           0       0.92      0.94      0.93       309\n",
      "\n",
      "    accuracy                           0.88       371\n",
      "   macro avg       0.79      0.75      0.77       371\n",
      "weighted avg       0.87      0.88      0.87       371\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classes = [1,0]\n",
    "\n",
    "display=ConfusionMatrixDisplay.from_predictions(\n",
    "    y_test, y_pred, labels=classes, cmap=plt.cm.BuGn)\n",
    "print(classification_report(y_test, y_pred, labels=classes))\n",
    "\n",
    "plt.title('Matriz de Confusión')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrica utilizada Balanced Accuracy \n",
    "\n",
    "The balanced accuracy in binary and multiclass classification problems to deal with imbalanced datasets. It is defined as the average of recall obtained on each class.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 44800 candidates, totalling 224000 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=DecisionTreeClassifier(random_state=42), n_jobs=-1,\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;],\n",
       "                         &#x27;max_depth&#x27;: array([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "       19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       "                         &#x27;min_samples_leaf&#x27;: array([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "       19, 20, 21]),\n",
       "                         &#x27;min_samples_split&#x27;: array([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "       19, 20, 21]),\n",
       "                         &#x27;splitter&#x27;: [&#x27;best&#x27;, &#x27;random&#x27;]},\n",
       "             scoring=&#x27;balanced_accuracy&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=DecisionTreeClassifier(random_state=42), n_jobs=-1,\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;],\n",
       "                         &#x27;max_depth&#x27;: array([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "       19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       "                         &#x27;min_samples_leaf&#x27;: array([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "       19, 20, 21]),\n",
       "                         &#x27;min_samples_split&#x27;: array([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "       19, 20, 21]),\n",
       "                         &#x27;splitter&#x27;: [&#x27;best&#x27;, &#x27;random&#x27;]},\n",
       "             scoring=&#x27;balanced_accuracy&#x27;, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=DecisionTreeClassifier(random_state=42), n_jobs=-1,\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': array([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "       19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       "                         'min_samples_leaf': array([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "       19, 20, 21]),\n",
       "                         'min_samples_split': array([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "       19, 20, 21]),\n",
       "                         'splitter': ['best', 'random']},\n",
       "             scoring='balanced_accuracy', verbose=1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tree.DecisionTreeClassifier(random_state=42)\n",
    "space = {\n",
    "    'criterion': ['gini','entropy'],\n",
    "    'splitter':[\"best\", \"random\"],\n",
    "    'max_depth': np.arange(2,30,1),\n",
    "    'min_samples_split':np.arange(2,22,1),\n",
    "    'min_samples_leaf':np.arange(2,22,1)\n",
    "}\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid1 = GridSearchCV(model, space, cv=5, verbose=1, n_jobs=-1,scoring='balanced_accuracy')\n",
    "grid1.fit(X_train, y_train) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy',\n",
       " 'max_depth': 21,\n",
       " 'min_samples_leaf': 2,\n",
       " 'min_samples_split': 2,\n",
       " 'splitter': 'random'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "treeCV1=tree.DecisionTreeClassifier(random_state=42,**grid1.best_params_)\n",
    "treeCV1.fit(X_train,y_train)\n",
    "y_pred=treeCV1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8652291105121294\n",
      "F1 Score: 0.5454545454545454\n",
      "Recall: 0.4838709677419355\n",
      "Precision: 0.625\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Precision:\", precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.48      0.55        62\n",
      "           0       0.90      0.94      0.92       309\n",
      "\n",
      "    accuracy                           0.87       371\n",
      "   macro avg       0.76      0.71      0.73       371\n",
      "weighted avg       0.85      0.87      0.86       371\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classes =[1, 0] \n",
    "\n",
    "display=ConfusionMatrixDisplay.from_predictions(\n",
    "    y_test, y_pred, labels=classes, cmap=plt.cm.BuGn)\n",
    "print(classification_report(y_test, y_pred, labels=classes))\n",
    "\n",
    "plt.title('Matriz de Confusión')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
